{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training\n",
    "- Â≠¶Áøí„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô\n",
    "- Ë®ÄË™û„É¢„Éá„É´„Å®„ÅØ\n",
    "- „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çí‰ΩøÁî®„Åó„Å™„ÅÑÊâãÊ≥ï(uni-gram, bi-gram)\n",
    "- Transformer‰ª•Ââç„ÅÆ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çí‰ΩøÁî®„Åó„ÅüË®ÄË™û„É¢„Éá„É´\n",
    "    - MLP\n",
    "    - RNN\n",
    "- Transformer„Çí‰ΩøÁî®„Åó„ÅüË®ÄË™û„É¢„Éá„É´\n",
    "    - Self-Attention„Å®Feedforward Network„ÅÆÂÆüË£Ö„ÄÅ‰∏¶ÂàóÂåñ\n",
    "    - GPT-2„ÅÆÂÆüË£Ö\n",
    "\n",
    "„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÅÆËß£Ë™¨„Éª„Ç®„É©„ÉºËß£Ê∂à„ÇÑÁî®Ë™û„ÅÆËß£Ë™¨GPT  \n",
    "https://chatgpt.com/g/g-H1Baw636t-mlxian-bei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: japanize-matplotlib in /home/keno.harada/miniconda3/lib/python3.12/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from japanize-matplotlib) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from matplotlib->japanize-matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/keno.harada/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install japanize-matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â≠¶Áøí„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô\n",
    "ChatGPT„ÅÆ„Çà„ÅÜ„Å™Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆÂ≠¶Áøí„Å´„ÅØÊñáÊõ∏„Éá„Éº„Çø„ÇíÂ§ßÈáè„Å´ÈõÜ„ÇÅ„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ  \n",
    "„Éá„Éº„Çø„ÅÆÈõÜ„ÇÅÊñπ„Å´„Çà„Å£„Å¶„É¢„Éá„É´„ÅÆÊÄßËÉΩ„ÅåÂ§ß„Åç„ÅèÂ∑¶Âè≥„Åï„Çå„Çã„ÅÆ„Åß„ÄÅÂ≠¶Áøí„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô„ÅØÈáçË¶Å„Å™Â∑•Á®ã„Åß„Åô„ÄÇ‰ª•‰∏ã„Å´ÂèÇËÄÉ„Å´„Å™„Çä„Åù„ÅÜ„Å™Ë´ñÊñá„ÇíËºâ„Åõ„Å¶„Åä„Åç„Åæ„Åô„ÄÇ  \n",
    "- [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://arxiv.org/abs/2402.00159)  \n",
    "- [FineWeb: decanting the web for the finest text data at scale](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)  \n",
    "- [Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance](https://arxiv.org/abs/2403.16952)  \n",
    "- [To Code, or Not To Code? Exploring Impact of Code in Pre-training](https://arxiv.org/abs/2408.10914)  \n",
    "- [Instruction Pre-Training: Language Models are Supervised Multitask Learners](https://arxiv.org/abs/2406.14491)  \n",
    "- [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)  \n",
    "- [Physics of Language Models: Part 3.1, Knowledge Storage and Extraction](https://arxiv.org/abs/2309.14316)  \n",
    "- [ÊùæÂ∞æ„ÉªÂ≤©Êæ§Á†îÁ©∂ÂÆ§„ÅßÈñãÂÇ¨„Åó„ÅüLLMÂãâÂº∑‰ºö„Åß„ÅÆÁô∫Ë°®Ë≥áÊñô](https://docs.google.com/presentation/d/14SeP11PcgmNcl93Xt0ziSynxdrOVd2WM/edit?usp=sharing&ouid=101802221278095300433&rtpof=true&sd=true)  \n",
    "\n",
    "‰ªäÂõû„ÅØ[LLM-jp„Å®„ÅÑ„ÅÜÂõ£‰Ωì](https://llm-jp.nii.ac.jp/)„ÅåÊï¥ÂÇô„Åó„Åü„Ç≥„Éº„Éë„Çπ„ÇíÂà©Áî®„Åó„Åæ„Åô„ÄÇ\n",
    "- https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v2/-/raw/main/ja/ja_wiki/train_9.jsonl.gz\n",
    "# !wget --no-check-certificate https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v2/-/raw/main/ja/ja_wiki/validation_0.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'meta'])\n",
      "„ÉÅ„É™„Ç≥„Ç∑„Éº„ÅØ„ÄÅ„Ç¢„É°„É™„Ç´ÂêàË°ÜÂõΩ„Ç™„Éè„Ç§„Ç™Â∑û‰∏≠Â§ÆÈÉ®Âçó„É≠„ÇπÈÉ°„ÅÆÈÉΩÂ∏Ç„Åß„ÅÇ„Çä„ÄÅÂêåÈÉ°„ÅÆÈÉ°Â∫ÅÊâÄÂú®Âú∞„Åß„ÅÇ„Çã„ÄÇ„Ç≥„É≠„É≥„Éê„ÇπÂ§ßÈÉΩÂ∏ÇÂúè„Å´Â±û„Åó„Å¶„ÅÑ„Çã„ÄÇ\n",
      "\n",
      "2010Âπ¥„ÅÆÂõΩÂã¢Ë™øÊüª„Åß„ÅØ‰∫∫Âè£21,901 ‰∫∫„Å†„Å£„Åü„ÄÇ„É≠„ÇπÈÉ°„Åß„ÅØÂîØ‰∏Ä„ÅÆÈÉΩÂ∏Ç„Åß\n",
      "{'id': '2973866', 'title': '„ÉÅ„É™„Ç≥„Ç∑„Éº („Ç™„Éè„Ç§„Ç™Â∑û)', 'url': 'https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%AA%E3%82%B3%E3%82%B7%E3%83%BC%20%28%E3%82%AA%E3%83%8F%E3%82%A4%E3%82%AA%E5%B7%9E%29'}\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "mini_train_data_file_num = 1000\n",
    "mini_train_data_text = \"\"\n",
    "file_count = 0\n",
    "with gzip.open('train_9.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        mini_train_data_text += data['text'] + \"\\n\"\n",
    "        file_count += 1\n",
    "        if file_count == mini_train_data_file_num:\n",
    "            break\n",
    "print(data.keys())\n",
    "print(data['text'][:100])\n",
    "print(data['meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'meta'])\n",
      "Ê¢∂Âéü ‰∏ÄÈ®éÔºà„Åã„Åò„Çè„Çâ „ÅÑ„Å£„Åç„ÄÅ1936Âπ¥9Êúà4Êó• - 1987Âπ¥1Êúà21Êó•Ôºâ„ÅØ„ÄÅÊó•Êú¨„ÅÆÊº´ÁîªÂéü‰ΩúËÄÖ„ÄÅÂ∞èË™¨ÂÆ∂„ÄÅÊò†Áîª„Éó„É≠„Éá„É•„Éº„Çµ„Éº„ÄÇÊú¨Âêç„ÅØÈ´òÊ£Æ ÊúùÊ®πÔºà„Åü„Åã„ÇÇ„Çä „ÅÇ„Åï„ÅçÔºâ„ÄÇÈ´òÊ£Æ ÊúùÈõÑÔºà„Åü„Åã„ÇÇ„Çä „ÅÇ„Åï„ÅäÔºâ„ÅÆÁ≠ÜÂêç\n",
      "{'id': '506', 'title': 'Ê¢∂Âéü‰∏ÄÈ®é', 'url': 'https://ja.wikipedia.org/wiki/%E6%A2%B6%E5%8E%9F%E4%B8%80%E9%A8%8E'}\n"
     ]
    }
   ],
   "source": [
    "val_data_file_num = 1\n",
    "val_data_text = \"\"\n",
    "file_count = 0\n",
    "with gzip.open('validation_0.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        val_data_text += data['text'] + \"\\n\"\n",
    "        file_count += 1\n",
    "        if file_count == val_data_file_num:\n",
    "            break\n",
    "print(data.keys())\n",
    "print(data['text'][:100])\n",
    "print(data['meta'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ë®ÄË™û„É¢„Éá„É´„Å®„ÅØ„ÄÄ„ÄÄ\n",
    "Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÅÆ\"Ë®ÄË™û„É¢„Éá„É´\"„Å®„ÅØ„ÄÅÂçòË™ûÂàó„ÅÆÂá∫ÁèæÁ¢∫Áéá„Çí„É¢„Éá„É´Âåñ„Åó„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ  \n",
    "Á¢∫Áéá„ÇíË®àÁÆó„Åß„Åç„Çã„ÅÆ„Åß„ÄÅ‰∏é„Åà„Çâ„Çå„ÅüÊñáÁ´†„Åå„Çà„ÅèË¶ã„ÇãÊñáÁ´†(Á¢∫Áéá„ÅåÈ´ò„ÅÑ)„Å™„ÅÆ„Åã„ÄÅÂ§â„Å™ÊñáÁ´†„Å™„ÅÆ„Åã(Á¢∫Áéá„Åå‰Ωé„ÅÑ)„ÇíÂà§Êñ≠„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åü„Çä„ÄÅÊñ∞„Åü„Å´ÊñáÁ´†„ÇíÁîüÊàê(Á¢∫Áéá„Å´Âæì„Å£„Å¶„Åè„ÅòÂºï„Åç„Çí„Åô„Çã)„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\n",
    "„Çà„ÇäËâØ„ÅÑË®ÄË™û„É¢„Éá„É´„ÅÆÈñãÁô∫„ÅÆ„Åü„ÇÅ„Å´„ÅØ„ÄÅ„Éá„Éº„Çø„Å®„Å©„ÅÆ„Çà„ÅÜ„Å´Á¢∫Áéá„Çí„É¢„Éá„É´Âåñ„Åô„Çã„Åã„ÅÆ„Éá„Ç∂„Ç§„É≥„ÅåÈáçË¶Å„Åß„Åô„ÄÇ\n",
    "### „Éá„Éº„Çø„Å´„Å§„ÅÑ„Å¶\n",
    "Ë®ÄË™û„É¢„Éá„É´„ÅØ„Éá„Éº„Çø„ÇíÂÖÉ„Å´Â≠¶Áøí„Åô„Çã„Åü„ÇÅ„ÄÅ„Åù„ÅÆ„Éá„Éº„Çø„Å´ÊúâÁõä„Å™ÊÉÖÂ†±(‰æã„Åà„Å∞Êó•Êú¨„ÅÆÊ≠¥Âè≤„ÇÑÊ≥ïÂæã„Å´Èñ¢„Åô„ÇãÊñáÁ´†)„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Å™„ÅÑ„Å®„ÄÅÂçòË™ûËá™Ë∫´„ÅÆÁêÜËß£„ÇÑÂçòË™ûÂêåÂ£´„ÅÆÈñ¢‰øÇÊÄß„ÇíÂ≠¶Áøí„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åõ„Çì„ÄÇ  \n",
    "‰∫∫Èñì„ÅåÊú¨„ÇíË™≠„Çì„Å†„Çä„ÄÅ‰∫∫„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„Å¶Êñ∞„Åó„ÅÑÁü•Ë≠ò„ÇíÂæó„Åü„Çä„ÄÅËâØ„ÅÑÊñáÁ´†„ÅÆÊõ∏„ÅçÊñπ„ÇíÂ≠¶„Çì„Å†„Çä„Åô„Çã„Çà„ÅÜ„Å´„ÄÅË®ÄË™û„É¢„Éá„É´„ÇÇ„Éá„Éº„Çø„ÇíÈÄö„Åò„Å¶Â≠¶Áøí„Åó„Åæ„Åô„ÄÇ\n",
    "### „É¢„Éá„É´Âåñ„Å´„Å§„ÅÑ„Å¶\n",
    "„Éá„Éº„Çø„ÇíÂæó„Åü„Å®„Åó„Å¶„ÇÇ„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å´Á¢∫Áéá„Çí„É¢„Éá„É´Âåñ„Åô„Çã„Åã„ÅÆ„Éá„Ç∂„Ç§„É≥„Åå„ÅÜ„Åæ„Åè„ÅÑ„Åã„Å™„ÅÑ„Å®„ÄÅËâØ„ÅÑË®ÄË™û„É¢„Éá„É´„ÅØ‰Ωú„Çå„Åæ„Åõ„Çì„ÄÇ\n",
    "- „Éá„Éº„Çø‰∏≠„ÅÆÊñáÂ≠ó„ÇíÊï∞„Åà‰∏ä„Åí„Å¶Ââç„ÅÆ1ÂçòË™û„Åã„ÇâÊ¨°„ÅÆ1ÂçòË™û„Çí‰∫àÊ∏¨„Åô„Çã„É¢„Éá„É´\n",
    "- „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆ‰∏ÄÁ®Æ„Åß„ÅÇ„ÇãMLP„ÇíÁî®„ÅÑ„Å¶„ÄÅÂâç„ÅÆÊï∞ÂçòË™û„Åã„ÇâÊ¨°„ÅÆ1ÂçòË™û„Çí‰∫àÊ∏¨„Åô„Çã„É¢„Éá„É´\n",
    "- Transformer„ÇíÁî®„ÅÑ„Å¶„ÄÅ„Çà„ÇäÈï∑„ÅÑÊñáËÑà„ÇíËÄÉÊÖÆ„Åó„Å¶Ê¨°„ÅÆÂçòË™û„Çí‰∫àÊ∏¨„Åô„Çã„É¢„Éá„É´  \n",
    "\n",
    "„ÇíÈñãÁô∫„Åó„Åæ„Åô„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çí‰ΩøÁî®„Åó„Å™„ÅÑ„ÄÅÊï∞„Åà‰∏ä„Åí„Å´„Çà„ÇãÊâãÊ≥ï(uni-gram, bi-gram)„ÅÆË®ÄË™û„É¢„Éá„É´"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram Ë®ÄË™û„É¢„Éá„É´\n",
    "$P\\left(w_1, \\ldots, w_m\\right)=\\prod_{i=1}^{i=m} P\\left(w_i \\mid w_1, \\ldots, w_{i-1}\\right) \\approx \\prod_{i=1}^{i=m} P\\left(w_i \\mid w_{i-n}, \\ldots, w_{i-1}\\right)$\n",
    "\n",
    "#### uni-gram„É¢„Éá„É´\n",
    "$P\\left(w_1, \\ldots, w_m\\right) \\approx \\prod_{i=1}^{i=m} P(w_i)$\n",
    "\n",
    "#### bi-gram„É¢„Éá„É´  \n",
    "$P\\left(w_1, \\ldots, w_m\\right)\\approx \\prod_{i=1}^{i=m} P\\left(w_i \\mid w_{i-1}\\right)$\n",
    "\n",
    "$P\\left(w_{i} \\mid w_{i-1}\\right)=\\frac{\\operatorname{count}\\left(w_{i}, w_{i-1}\\right)}{\\operatorname{count}\\left(w_{i}\\right)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„ÄéÂãù„Å§„ÅãÊ≠ª„Å¨„Åã„Äè„ÅØHBO(Êó•Êú¨„Åß„ÅØ„Çπ„Çø„Éº„Éª„ÉÅ„É£„É≥„Éç„É´„ÅåÊîæÈÄÅ)„ÅÆ„Éï„Ç°„É≥„Çø„Ç∏„Éº„Éª„Éâ„É©„Éû„Éª„Ç∑„É™„Éº„Ç∫„Åß„ÅÇ„Çã„Äé„Ç≤„Éº„É†„Éª„Ç™„Éñ„Éª„Çπ„É≠„Éº„É≥„Ç∫„Äè„ÅÆÁ¨¨1Á´†„Äé‰∏ÉÁéãÂõΩÊà¶Ë®ò„Äè„ÅÆÁ¨¨7Ë©±„Åß„ÅÇ„Çã„ÄÇ„Éó„É≠„Éá„É•„Éº„Çµ„Éº„Åß„ÇÇ„ÅÇ„Çã„Éá„Ç§„É¥„Ç£„ÉÉ„Éâ„Éª\n",
      "------------------------\n",
      "ÂÖ®‰Ωì„ÅÆÊñáÂ≠óÊï∞:  1569582\n",
      "ÊñáÂ≠ó„ÅÆÁ®ÆÈ°û:  3807\n"
     ]
    }
   ],
   "source": [
    "print(mini_train_data_text[:100])\n",
    "print('------------------------')\n",
    "print('ÂÖ®‰Ωì„ÅÆÊñáÂ≠óÊï∞: ', len(mini_train_data_text))\n",
    "print('ÊñáÂ≠ó„ÅÆÁ®ÆÈ°û: ', len(set(mini_train_data_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âá∫ÁèæÈ†ªÂ∫¶„ÅÆÈ´ò„ÅÑÊñáÂ≠ó\n",
      "[(' ', 53441), ('\\n', 44189), ('„ÅÆ', 38675), ('„ÄÅ', 30453), ('„Éº', 29588)]\n",
      "\n",
      "'Êó•'„ÅÆÁ¢∫Áéá = 'Êó•'„ÅÆÂá∫ÁèæÂõûÊï∞ √∑ ÂÖ®‰Ωì„ÅÆÊñáÂ≠óÊï∞ =  7361 √∑ 1569582 = 0.004689783649404746\n",
      "'Êó•Êú¨'„ÅÆÁ¢∫Áéá = 'Êó•'„ÅÆÁ¢∫Áéá x 'Êú¨'„ÅÆÁ¢∫Áéá = 0.004689783649404746 x 0.001984604818352912 = 9.307367227641361e-06\n",
      "'Êó•Êõú'„ÅÆÁ¢∫Áéá = 'Êó•'„ÅÆÁ¢∫Áéá x 'Êõú'„ÅÆÁ¢∫Áéá = 0.004689783649404746 x 0.00018093989355127672 = 8.485689543018127e-07\n"
     ]
    }
   ],
   "source": [
    "character_count = {}\n",
    "for character in mini_train_data_text:\n",
    "    character_count[character] = character_count.get(character, 0) + 1\n",
    "# Âá∫ÁèæÈ†ªÂ∫¶„ÅÆÈ´ò„ÅÑÊñáÂ≠ó„Çí‰∏ä‰Ωç5ÂÄãË°®Á§∫\n",
    "print('Âá∫ÁèæÈ†ªÂ∫¶„ÅÆÈ´ò„ÅÑÊñáÂ≠ó')\n",
    "print(sorted(character_count.items(), key = lambda kv: -kv[1])[:5])\n",
    "\n",
    "# ÈÅéÂéª„ÅÆÊÉÖÂ†±„ÇíËÄÉÊÖÆ„Åó„Å™„ÅÑuni-gram„É¢„Éá„É´\n",
    "print()\n",
    "total_count = sum(character_count.values())\n",
    "ch_0 = 'Êó•'\n",
    "ch_1 = 'Êú¨'\n",
    "ch_2 = 'Êõú'\n",
    "print(f\"'{ch_0}'„ÅÆÁ¢∫Áéá = '{ch_0}'„ÅÆÂá∫ÁèæÂõûÊï∞ √∑ ÂÖ®‰Ωì„ÅÆÊñáÂ≠óÊï∞ =  {character_count[ch_0]} √∑ {total_count} = {character_count[ch_0] / total_count}\")\n",
    "print(f\"'{ch_0 + ch_1}'„ÅÆÁ¢∫Áéá = '{ch_0}'„ÅÆÁ¢∫Áéá x '{ch_1}'„ÅÆÁ¢∫Áéá = {character_count[ch_0] / total_count} x {character_count[ch_1] / total_count} = {character_count[ch_0] * character_count[ch_1] / total_count ** 2}\")\n",
    "print(f\"'{ch_0 + ch_2}'„ÅÆÁ¢∫Áéá = '{ch_0}'„ÅÆÁ¢∫Áéá x '{ch_2}'„ÅÆÁ¢∫Áéá = {character_count[ch_0] / total_count} x {character_count[ch_2] / total_count} = {character_count[ch_0] * character_count[ch_2] / total_count ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Âá∫ÁèæÁ¢∫Áéá„ÅÆÂèØË¶ñÂåñ\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "total_count = sum(character_count.values())\n",
    "# ‰∏ä‰Ωç30ÊñáÂ≠ó„ÅÆÂá∫ÁèæÈ†ªÂ∫¶„ÇíÂèñ„Çã\n",
    "top_k = 30\n",
    "top_k_key = sorted(character_count.keys(), key = lambda k: -character_count[k])[:top_k]\n",
    "top_k_value = [character_count[k] for k in top_k_key]\n",
    "top_k_probability = [v / total_count for v in top_k_value]\n",
    "\n",
    "# xËª∏„Å´ÊñáÂ≠ó„ÄÅyËª∏„Å´Âá∫ÁèæÈ†ªÂ∫¶„ÇíÂèñ„Çã\n",
    "plt.bar(top_k_key, top_k_probability)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "' '\n",
      "'„ÄéÂãù„Å§„Åã                    '\n"
     ]
    }
   ],
   "source": [
    "# ÁîüÊàê\n",
    "# greedy decoding\n",
    "max_tokens = 20\n",
    "generated_text = '„ÄéÂãù„Å§„Åã'\n",
    "for _ in range(max_tokens):\n",
    "    next_char = max(character_count, key=lambda k: character_count[k]) # ÊúÄ„ÇÇÂá∫ÁèæÈ†ªÂ∫¶„ÅåÈ´ò„ÅÑÊñáÂ≠ó„ÇíÈÅ∏Êäû, greedy decoding\n",
    "    print(repr(next_char))\n",
    "    generated_text += next_char\n",
    "\n",
    "print(repr(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'„Ç∑'\n",
      "'„Éà'\n",
      "'„ÄÅ'\n",
      "'Âåñ'\n",
      "'‰ªª'\n",
      "'Áúå'\n",
      "'„Å®'\n",
      "'ÂÆö'\n",
      "'„Ç¢'\n",
      "'‰Ωç'\n",
      "'„ÅÆ'\n",
      "'„ÅÑ'\n",
      "'„Å£'\n",
      "'Êúà'\n",
      "'L'\n",
      "'„Åß'\n",
      "'„ÄÅ'\n",
      "'„Åæ'\n",
      "'Á∂ö'\n",
      "'H'\n",
      "'„ÄéÂãù„Å§„Åã„Ç∑„Éà„ÄÅÂåñ‰ªªÁúå„Å®ÂÆö„Ç¢‰Ωç„ÅÆ„ÅÑ„Å£ÊúàL„Åß„ÄÅ„ÅæÁ∂öH'\n"
     ]
    }
   ],
   "source": [
    "# top_p sampling\n",
    "import random\n",
    "max_tokens = 20\n",
    "top_p = 0.9\n",
    "generated_text = '„ÄéÂãù„Å§„Åã'\n",
    "for _ in range(max_tokens):\n",
    "    sorted_character_count = sorted(character_count.items(), key=lambda kv: -kv[1])\n",
    "    cumulative_probability = 0\n",
    "    vocab = []\n",
    "    vocab_count = []\n",
    "    vocab_total_count = 0\n",
    "    for character, count in sorted_character_count:\n",
    "        cumulative_probability += count / total_count\n",
    "        if cumulative_probability > top_p:\n",
    "            break\n",
    "        vocab.append(character)\n",
    "        vocab_count.append(count)\n",
    "        vocab_total_count += count\n",
    "    probablity = [count / vocab_total_count for count in vocab_count]\n",
    "    next_char = random.choices(vocab, probablity)[0]\n",
    "    print(repr(next_char))\n",
    "    generated_text += next_char\n",
    "print(repr(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Tokenizer„ÅÆË®≠Ë®à„ÇÇÈáçË¶Å„Åß„Åô„ÄÅ‰ª•‰∏ã„Å´ÂèÇËÄÉ„Å®„Å™„Çã„É™„É≥„ÇØ„ÇíËºâ„Åõ„Å¶„Åä„Åç„Åæ„Åô„ÄÇ  \n",
    "- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)  \n",
    "- [Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies](https://arxiv.org/abs/2407.13623)  \n",
    "- [ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models](https://arxiv.org/abs/2105.13626)  \n",
    "- GPT„Ç∑„É™„Éº„Ç∫„ÅÆTokenizer: https://github.com/openai/tiktoken\n",
    "- Llama2„ÇÑLLM-jp„ÅÆtokenizer„Çí‰ΩúÊàê„Åô„ÇãÈöõ„Å´Âà©Áî®: https://github.com/google/sentencepiece\n",
    "- Byte Pair Encoding„ÅÆÂÆüË£Ö: https://github.com/kenoharada/language-model-from-scratch/blob/main/notebooks/Ja/Tokenizer.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3310, 3354, 694, 667, 703, 591, 1027, 1621, 592, 2156, 568, 549, 584, 570, 526]\n"
     ]
    }
   ],
   "source": [
    "unique_chars_in_train_text = sorted(list(set(mini_train_data_text)))\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, chars):\n",
    "        self.str_to_idx = dict()\n",
    "        self.str_to_idx['<|endoftext|>'] = 0\n",
    "        # utf-8\n",
    "        for i in range(256):\n",
    "            if f'<utf8_{i}>' not in self.str_to_idx:\n",
    "                self.str_to_idx[f'<utf8_{i}>'] = len(self.str_to_idx)\n",
    "        for char in chars:\n",
    "            self.str_to_idx[char] = len(self.str_to_idx)\n",
    "        self.idx_to_str = dict()\n",
    "        for key, value in self.str_to_idx.items():\n",
    "            self.idx_to_str[value] = key\n",
    "    \n",
    "    def encode(self, text, eot=False):\n",
    "        result = []\n",
    "        for char in text:\n",
    "            if char not in self.str_to_idx:\n",
    "                utf_8_num = list(char.encode(\"utf-8\"))\n",
    "                for num in utf_8_num:\n",
    "                    result.append(self.str_to_idx[f'<utf8_{num}>'])\n",
    "            else:\n",
    "                result.append(self.str_to_idx[char])\n",
    "        if eot:\n",
    "            result.append(self.str_to_idx['<|endoftext|>'])\n",
    "        return result\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        decoded_with_utf_token = [self.idx_to_str[token] for token in tokens]\n",
    "        decoded_postprocess_utf = []\n",
    "        utf_tokens = []\n",
    "        for token in decoded_with_utf_token:\n",
    "            if token.startswith(\"<utf8_\"):\n",
    "                utf_num = int(token.replace(\"<utf8_\", \"\").replace(\">\", \"\"))\n",
    "                utf_tokens.append(utf_num)\n",
    "            else:\n",
    "                if utf_tokens:\n",
    "                    decoded_postprocess_utf.append(bytes(utf_tokens).decode(\"utf-8\"))\n",
    "                    utf_tokens = []\n",
    "                decoded_postprocess_utf.append(token)\n",
    "        if utf_tokens:\n",
    "            decoded_postprocess_utf.append(bytes(utf_tokens).decode(\"utf-8\"))\n",
    "            utf_tokens = []\n",
    "        return \"\".join(decoded_postprocess_utf)\n",
    "    \n",
    "    def decode_with_utf(self, tokens):\n",
    "        return \"\".join([self.idx_to_str[token] for token in tokens])\n",
    "\n",
    "tokenizer = Tokenizer(unique_chars_in_train_text) # Tokenizer„ÅÆÂàùÊúüÂåñ„ÄÅ‰∏ÄËà¨ÁöÑ„Å´„ÅØByte Pair Encoding„ÇÑUnigram Language Model„Å™„Å©„ÇíÊ¥ªÁî®„Åó„Å¶Tokenizer„ÇíÂÆüË£Ö„Åô„Çã\n",
    "text = 'Ë®ÄË™û„É¢„Éá„É´„ÅÆÂãâÂº∑„ÅØÊ•Ω„Åó„ÅÑ„Åß„Åô„ÄÇ'\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Â≠¶ÁøíÁî®„Éá„Éº„Çø„Å´„ÅÇ„ÇãË™û\n",
    "'Êó•' in unique_chars_in_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1954], 'Êó•', 'Êó•')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Êó•'), tokenizer.decode_with_utf([1954]), tokenizer.decode_with_utf([1954])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Â≠¶ÁøíÁî®„Éá„Éº„Çø„Å´„Å™„ÅÑÊú™Áü•Ë™û\n",
    "'üòÑ' in unique_chars_in_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([241, 160, 153, 133], '<utf8_240><utf8_159><utf8_152><utf8_132>', 'üòÑ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('üòÑ'), tokenizer.decode_with_utf([241, 160, 153, 133]), tokenizer.decode([241, 160, 153, 133])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âá∫ÁèæÈ†ªÂ∫¶„ÅÆÈ´ò„ÅÑbigram\n",
      "[((258, 259), 14841), ((526, 258), 10469), ((258, 258), 9382), ((620, 526), 8329), ((277, 275), 7166), ((259, 272), 6726), ((272, 259), 6423), ((576, 526), 5829), ((583, 549), 5599), ((568, 583), 5552)]\n",
      "'\\n' ' ' 14841\n",
      "'„ÄÇ' '\\n' 10469\n",
      "'\\n' '\\n' 9382\n",
      "'„Çã' '„ÄÇ' 8329\n",
      "'2' '0' 7166\n",
      "' ' '-' 6726\n",
      "'-' ' ' 6423\n",
      "'„Åü' '„ÄÇ' 5829\n",
      "'„Å¶' '„ÅÑ' 5599\n",
      "'„Åó' '„Å¶' 5552\n"
     ]
    }
   ],
   "source": [
    "# bi-gram„É¢„Éá„É´\n",
    "bigram_count = {}\n",
    "mini_train_data_tokens = []\n",
    "mini_train_data_file_num = 1000\n",
    "mini_train_data_text = \"\"\n",
    "file_count = 0\n",
    "\n",
    "with gzip.open('train_9.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        mini_train_data_tokens += tokenizer.encode(data['text'], eot=True)\n",
    "        file_count += 1\n",
    "        if file_count == mini_train_data_file_num:\n",
    "            break\n",
    "\n",
    "val_data_tokens = []\n",
    "val_data_file_num = 1\n",
    "val_data_text = \"\"\n",
    "file_count = 0\n",
    "with gzip.open('validation_0.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        val_data_tokens += tokenizer.encode(data['text'], eot=True)\n",
    "        file_count += 1\n",
    "        if file_count == val_data_file_num:\n",
    "            break\n",
    "\n",
    "for i in range(len(mini_train_data_tokens) - 1):\n",
    "    bigram = (mini_train_data_tokens[i], mini_train_data_tokens[i+1])\n",
    "    bigram_count[bigram] = bigram_count.get(bigram, 0) + 1\n",
    "\n",
    "# top-k„ÅÆbigram„ÇíË°®Á§∫\n",
    "print('Âá∫ÁèæÈ†ªÂ∫¶„ÅÆÈ´ò„ÅÑbigram')\n",
    "top_k = 10\n",
    "top_k_bigram = sorted(bigram_count.items(), key = lambda kv: -kv[1])[:top_k]\n",
    "print(top_k_bigram)\n",
    "# decode„Åó„Å¶Á¢∫Ë™ç\n",
    "for bigram, count in top_k_bigram:\n",
    "    print(repr(tokenizer.decode([bigram[0]])), repr(tokenizer.decode([bigram[1]])), count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'„ÅÑ'\n",
      "'„Çã'\n",
      "'„ÄÇ'\n",
      "'\\n'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "[536, 1032, 581, 549, 620, 526, 258, 259, 272, 259, 272, 259, 272, 259, 272, 259, 272, 259, 272, 259, 272, 259, 272]\n",
      "„ÄéÂãù„Å§„ÅÑ„Çã„ÄÇ\n",
      " - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "# ÁîüÊàê\n",
    "# greedy decoding\n",
    "max_tokens = 20\n",
    "generated_text = '„ÄéÂãù„Å§„Åã'\n",
    "generated_tokens = tokenizer.encode(generated_text)[:-1]\n",
    "for _ in range(max_tokens):\n",
    "    next_token = max(bigram_count, key=lambda k: bigram_count[k] if k[0] == generated_tokens[-1] else 0) # Áõ¥Ââç„ÅÆÊñáÂ≠ó„ÅåÊù•„Åü„Å®„Åç„ÅÆÊ¨°„ÅÆÊñáÂ≠ó„ÅÆÂá∫ÁèæÈ†ªÂ∫¶„ÅåÊúÄ„ÇÇÈ´ò„ÅÑ„ÇÇ„ÅÆ„ÇíÈÅ∏Êäû\n",
    "    generated_tokens.append(next_token[1])\n",
    "    print(repr(tokenizer.decode([next_token[1]])))\n",
    "print(generated_tokens)\n",
    "print(tokenizer.decode(generated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "\n",
    "\n",
    "class Ngram:\n",
    "    def __init__(self, n, vocab, laplace=1):\n",
    "        self.n = n\n",
    "        self.vocab = vocab\n",
    "        self.laplace = laplace\n",
    "        self.ngram = defaultdict(lambda: laplace)\n",
    "        self.context_count = defaultdict(lambda: laplace * len(self.vocab))\n",
    "    \n",
    "    def train(self, token_list):\n",
    "        assert isinstance(token_list, list)\n",
    "        for i in range(len(token_list) - self.n + 1):\n",
    "            ngram_list = copy.deepcopy(token_list[i:i+self.n])\n",
    "            ngram_list = [str(i) for i in ngram_list]\n",
    "            context = ngram_list[:-1]\n",
    "            ngram_key = '-'.join(ngram_list)\n",
    "            context_key = '-'.join(context)\n",
    "            self.ngram[ngram_key] += 1\n",
    "            self.context_count[context_key] += 1\n",
    "    \n",
    "\n",
    "    def train_batch(self, token_list):\n",
    "        for tokens in token_list:\n",
    "            self.train(tokens)\n",
    "    \n",
    "    def get_prob(self, ngram):\n",
    "        if self.n == 1:\n",
    "            return self.ngram[ngram] / len(self.vocab)\n",
    "        else:\n",
    "            context = ngram.split('-')[:-1]\n",
    "            context = '-'.join(context)\n",
    "            return self.ngram[ngram] / self.context_count[context]\n",
    "    \n",
    "    def get_prob_distribution(self, n_minus_1_gram):\n",
    "        distribution = []\n",
    "        distribution_dict = {}\n",
    "        for word in self.vocab:\n",
    "            ngram_list = n_minus_1_gram + [word]\n",
    "            ngram = '-'.join([str(i) for i in ngram_list])\n",
    "            # print('hi', ngram)\n",
    "            distribution.append(self.get_prob(ngram))\n",
    "            distribution_dict[word] = self.get_prob(ngram)\n",
    "        return distribution, distribution_dict\n",
    "    \n",
    "    def forward(self, token_indexes):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        if isinstance(token_indexes, torch.Tensor) or isinstance(token_indexes, torch.LongTensor):\n",
    "            token_indexes = token_indexes.tolist()\n",
    "        assert isinstance(token_indexes, list)\n",
    "        batch_size = len(token_indexes)\n",
    "        sequence_length = len(token_indexes[0])\n",
    "        distributions = torch.ones(batch_size, sequence_length, len(self.vocab))\n",
    "        distributions /= len(self.vocab)\n",
    "        for i in range(sequence_length):\n",
    "            for batch in range(batch_size):\n",
    "                if self.n == 2:\n",
    "                    context = [token_indexes[batch][i]]\n",
    "                else:\n",
    "                    if i < self.n - 1:\n",
    "                        if i == 0:\n",
    "                            context = [token_indexes[batch][i]]\n",
    "                        else:\n",
    "                            context = token_indexes[batch][:i+1]\n",
    "                    else:\n",
    "                        context = token_indexes[batch][i-self.n+2:i+1]\n",
    "                distribution, _ = self.get_prob_distribution(context)\n",
    "                distributions[batch, i] = torch.tensor(distribution)\n",
    "        # distributions: (batch_size, sequence_length, vocab_size)\n",
    "        return distributions\n",
    "    \n",
    "    def loss(self, token_indexes, targets):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        distributions = self.forward(token_indexes)\n",
    "        distributions = distributions.to(targets.device)\n",
    "        log_distributions = torch.log(distributions)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length, vocab_size = log_distributions.shape\n",
    "        loss = F.nll_loss(\n",
    "            log_distributions.view(batch_size*sequence_length, vocab_size),\n",
    "            targets.view(batch_size*sequence_length)\n",
    "            )\n",
    "        # loss: scalar\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, token_indexes, max_length=10):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        for _ in range(max_length):\n",
    "            distributions = self.forward(token_indexes)\n",
    "            distributions = distributions[0, -1]\n",
    "            # greedy decoding\n",
    "            next_token = torch.argmax(distributions).item()\n",
    "            token_indexes[0].append(next_token)\n",
    "        return token_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„Éë„É©„É°„Éº„ÇøÊï∞: 16516096\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "parameters = len(tokenizer.str_to_idx) ** n\n",
    "print(f'„Éë„É©„É°„Éº„ÇøÊï∞: {parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'„Äé'\n",
      "'Âãù'\n",
      "'„Å§'\n",
      "'„Åã'\n",
      "'„Çâ'\n",
      "'„Çå'\n",
      "'„Åü'\n",
      "'„ÄÇ'\n",
      "'\\n'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n",
      "'-'\n",
      "' '\n"
     ]
    }
   ],
   "source": [
    "ngram = Ngram(2, tokenizer.str_to_idx.values())\n",
    "ngram.train(mini_train_data_tokens)\n",
    "generated_text = '„ÄéÂãù„Å§„Åã'\n",
    "context_token_indexes = [tokenizer.encode(generated_text)]\n",
    "generated_tokens = ngram.generate(context_token_indexes, max_length=20)\n",
    "for token in generated_tokens[0]:\n",
    "    print(repr(tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.082467079162598"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 512\n",
    "input_tokens = val_data_tokens[:context_length]\n",
    "target_tokens = val_data_tokens[1:context_length+1]\n",
    "ngram.loss([input_tokens], torch.tensor([target_tokens])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'„Äé'\n",
      "'Âãù'\n",
      "'„Å§'\n",
      "'„Åã'\n",
      "'Ê≠ª'\n",
      "'„Å¨'\n",
      "'„Åã'\n",
      "'„Äè'\n",
      "'„ÅØ'\n",
      "'H'\n",
      "'B'\n",
      "'O'\n",
      "'('\n",
      "'Êó•'\n",
      "'Êú¨'\n",
      "'„Åß'\n",
      "'„ÅØ'\n",
      "'„Çπ'\n",
      "'„Çø'\n",
      "'„Éº'\n",
      "'„Éª'\n",
      "'„Ç¶'\n",
      "'„Ç©'\n"
     ]
    }
   ],
   "source": [
    "ngram = Ngram(4, tokenizer.str_to_idx.values())\n",
    "ngram.train(mini_train_data_tokens)\n",
    "generated_text = '„ÄéÂãù„Å§„Åã'\n",
    "context_token_indexes = [tokenizer.encode(generated_text)[:-1]]\n",
    "generated_tokens = ngram.generate(context_token_indexes, max_length=20)\n",
    "for token in generated_tokens[0]:\n",
    "    print(repr(tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.280468463897705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 512\n",
    "input_tokens = val_data_tokens[:context_length]\n",
    "target_tokens = val_data_tokens[1:context_length+1]\n",
    "ngram.loss([input_tokens], torch.tensor([target_tokens])).item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çí‰ΩøÁî®„Åó„ÅüË®ÄË™û„É¢„Éá„É´„ÄÄ„ÄÄ\n",
    "Ë®ÄË™û„É¢„Éá„É´„Çí„Éá„Ç∂„Ç§„É≥„Åô„ÇãÈöõ„Å´„ÄÅÈÅéÂéª„ÅÆÊñáËÑà„ÇíËÄÉÊÖÆ„Åô„Çã„Å®„Çà„ÇäËá™ÁÑ∂„Å™ÊñáÁ´†„ÅÆ„É¢„Éá„É™„É≥„Ç∞„Åå„Åß„Åç„Çã„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ  \n",
    "„Åü„Å†„ÄÅN-gram„É¢„Éá„É´„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞„ÅÆ„Ç™„Éº„ÉÄ„Éº„ÅØ„ÄÅ$O\\left(\\left|V\\right|^n\\right)$„ÄÄ„Å®„Å™„Çä„ÄÅÈÅéÂéª„ÅÆÊñáËÑà„ÅåÂ¢ó„Åà„Çå„Å∞Â¢ó„Åà„Çã„Åª„Å©ÁµÑ„ÅøÂêà„Çè„Åõ„ÅåËÜ®Â§ß„Å´„Å™„Çä„Åæ„Åô„ÄÇ  \n",
    "ÁµÑ„ÅøÂêà„Çè„ÅõÂçò‰Ωç„ÅßÊï∞„Åà‰∏ä„Åí„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ„Éá„Éº„Çø‰∏≠„Å´Âá∫Áèæ„Åó„Å™„ÅÑÁµÑ„ÅøÂêà„Çè„Åõ„Åå„ÅÇ„Çã„Å®„ÄÅ„Åù„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„ÅÆÁ¢∫Áéá„ÅØ0„Å®„Å™„Çä„ÄÅ„Åù„ÅÆÂæå„ÅÆ‰∫àÊ∏¨„Åå„Åß„Åç„Å™„Åè„Å™„Å£„Å¶„Åó„Åæ„ÅÑ„Åæ„Åô„ÄÇ  \n",
    "\n",
    "„Åæ„Åü„ÄÅÁµÑ„ÅøÂêà„Çè„ÅõÂà•„ÅÆÊï∞„Åà‰∏ä„Åí„Åß„ÅØ„ÄÅÂçòË™û„ÉªÊñáËÑà„Çí„Åù„Çå„Åû„ÇåÁã¨Á´ã„Åó„Åü„ÇÇ„ÅÆ„Å®„Åó„Å¶Êâ±„Å£„Å¶„Åä„Çä„ÄÅÂçòË™û„ÅÆÊÑèÂë≥„ÇÑÊñáËÑà„ÇíÂÖ±Êúâ„Åó„ÅüË°®Áèæ„ÅåÂæó„Çâ„Çå„Åæ„Åõ„Çì„ÄÇ\n",
    "\n",
    "Ëß£Ê±∫Á≠ñ„Å®„Åó„Å¶ÁµÑ„ÅøÂêà„Çè„Åõ„ÅÆË°®„Å´„Çà„Çã„É¢„Éá„É´Âåñ„Åß„ÅØ„Å™„Åè„ÄÅ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Å®ÂçòË™û„Éô„ÇØ„Éà„É´„ÅÆË°®Áèæ„ÇíÁî®„ÅÑ„Çã„Åì„Å®„Åß„É¢„Éá„É´Âåñ„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ\n",
    "\n",
    "„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÂ≠¶Áøí„ÅÆÈöõ„Å´Ë°å„ÅÜ„ÄÅÊ¨°ÂçòË™û‰∫àÊ∏¨„Å´„Çà„Å£„Å¶ÂçòË™û„Éô„ÇØ„Éà„É´„Å´„ÅØÂçòË™û„ÅÆÊÑèÂë≥„ÇÑÊ¶ÇÂøµ„Åå‰ªò‰∏é„Åï„Çå„ÄÅ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆ„Éë„É©„É°„Éº„Çø„Å´„ÅØÂçòË™ûÂêåÂ£´„ÅÆÈñ¢‰øÇÊÄß„ÅåÂ≠¶Áøí„Åï„Çå„Çã„Åì„Å®„ÅåÊúüÂæÖ„Åï„Çå„Åæ„Åô„ÄÇ\n",
    "\n",
    "Êó•Êú¨„ÅßÊúÄ„ÇÇÈ´ò„ÅÑÂ±±„ÅØ„ÄåÔºü„Äç„ÅÆÔºü„ÇíÂΩì„Å¶„Çã„Åü„ÇÅ„Å´„ÄÅ\n",
    "- Ôºü„Å´„ÅØÊñáÊ≥ïÁöÑ„Å´ÂêçË©û„ÅåÂÖ•„Çã\n",
    "- „Åù„ÅÆÂÄôË£ú„ÅØÊñáËÑàÁöÑ„Å´Â±±„Åß„ÅÇ„Çä\n",
    "- Êó•Êú¨„ÅßÊúÄ„ÇÇÈ´ò„ÅÑ„Å®„ÅÑ„ÅÜÊÉÖÂ†±„Åå„ÅÇ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Çà„ÅÜ„Å™ÊñáËÑà‰∏ä„ÅÆ„Å©„ÅÆÊÉÖÂ†±„Å´ÁùÄÁõÆ„Åô„Çã„Åã\n",
    "- ÊñáËÑà„ÇíË∏è„Åæ„Åà„Åü‰∏ä„Åß‰ªä„Åæ„ÅßÂæó„ÅüÁü•Ë≠ò„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´ÁµÑ„ÅøÂêà„Çè„Åõ„Çã„Åã\n",
    "\n",
    "„Å®„ÅÑ„ÅÜ„Åì„Å®„Çí„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅåÂ≠¶Áøí„Åó„Åæ„Åô„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP„Å´„Çà„Çã„É¢„Éá„É´Âåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        # ÂçòË™û„Éô„ÇØ„Éà„É´„ÅÆÂèñÂæó\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "        # FeedForward Layer\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "            )\n",
    "        # vocab_size„Å∏„ÅÆÂ§âÊèõ\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "        print('number of parameters:', sum(p.numel() for p in self.parameters()))\n",
    "    \n",
    "    def forward(self, token_indexes):\n",
    "        # token_index: (batch_size, sequence_length)\n",
    "        embedding = self.token_embedding_table(token_indexes)\n",
    "        logits = self.linear(self.ff(embedding))\n",
    "        # logits: (batch_size, sequence_length, vocab_size)\n",
    "        return logits\n",
    "\n",
    "    def loss_per_token(self, token_indexes, targets):\n",
    "        logits = self(token_indexes)\n",
    "        # logits: (batch_size, sequence_length, vocab_size)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length, vocab_size = logits.shape\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(batch_size*sequence_length, vocab_size),\n",
    "            targets.view(batch_size*sequence_length),\n",
    "            reduction='none'\n",
    "            )\n",
    "        # loss: (batch_size*sequence_length)\n",
    "        return loss.view(batch_size, sequence_length)\n",
    "    \n",
    "    def loss(self, token_indexes, targets):\n",
    "        logits = self(token_indexes)\n",
    "        # logits: (batch_size, sequence_length, vocab_size)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length, vocab_size = logits.shape\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(batch_size*sequence_length, vocab_size),\n",
    "            targets.view(batch_size*sequence_length)\n",
    "            )\n",
    "        # loss: scalar\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, token_indexes, max_new_tokens):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length = token_indexes.shape\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(token_indexes)\n",
    "            # logits: (batch_size, sequence_length, vocab_size)\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            # next_token_logits: (batch_size, vocab_size)\n",
    "            next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
    "            # next_token_probs: (batch_size, vocab_size)\n",
    "            # greedy decoding\n",
    "            next_token = torch.argmax(next_token_probs, dim=-1, keepdim=True)\n",
    "            # next_token = torch.multinomial(next_token_probs, num_samples=1)\n",
    "            # next_token: (batch_size, 1)\n",
    "            token_indexes = torch.cat([token_indexes, next_token], dim=1)\n",
    "            # token_indexes: (batch_size, sequence_length+1)\n",
    "        return token_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 36724\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.str_to_idx)\n",
    "d_model = 4\n",
    "d_ff = d_model * 4\n",
    "nn_lm = BigramLanguageModel(vocab_size, d_model, d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 536, 1032,  581]])\n",
      "„ÄéÂãù„Å§\n",
      "tensor([[1032,  581,  556]])\n",
      "Âãù„Å§„Åã\n"
     ]
    }
   ],
   "source": [
    "text = '„ÄéÂãù„Å§„Åã'\n",
    "token_indexes = torch.tensor([tokenizer.encode(text)])\n",
    "input_token_indexes = token_indexes[:, :-1]\n",
    "target_token_indexes = token_indexes[:, 1:]\n",
    "print(input_token_indexes)\n",
    "print(tokenizer.decode(input_token_indexes[0].tolist()))\n",
    "\n",
    "print(target_token_indexes)\n",
    "print(tokenizer.decode(target_token_indexes[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4086, -1.4731,  0.8040, -0.1425],\n",
      "         [-0.8011,  0.0812, -1.1384, -0.4476],\n",
      "         [ 1.3060, -1.2617, -0.0670,  0.2999]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = nn_lm.token_embedding_table(input_token_indexes)\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 536, 1032,  581,  556, 3504, 2662, 2686, 1259, 1436, 2741, 1904, 1904,\n",
       "         1904, 1904]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_lm.generate(token_indexes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂÖ•Âäõ: „Äé ‚Üí Token id: 536 ‚Üí Token embedding: [0.40859851241111755, -1.4730736017227173, 0.8040308952331543, -0.1425115317106247] \n",
      "‚Üí Neural Net ‚Üí \n",
      "1032: 0.000, 1436: 0.000, 2776: 0.000, 1259: 0.000 <---Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã---> Target: 1032: 1, 1436: 0, 2776: 0, 1259: 0\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"ÂÖ•Âäõ: {input_text} ‚Üí Token id: {input_token_id} ‚Üí Token embedding: {token_embeddings} \n",
    "‚Üí Neural Net ‚Üí \n",
    "{next_token_prediction_prob} <---Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã---> Target: {target_prob}\"\"\"\n",
    "for idx, token in enumerate(input_token_indexes[0]):\n",
    "    input_text = tokenizer.decode([input_token_indexes[0].tolist()[idx]])\n",
    "    input_token_id = token.item()\n",
    "    token_embeddings = nn_lm.token_embedding_table(token.unsqueeze(0)).squeeze().detach().numpy().tolist()\n",
    "    next_token_prediction = nn_lm(token.unsqueeze(0))\n",
    "    next_token_prediction = F.softmax(next_token_prediction, dim=-1)\n",
    "    next_token_prediction_top_k_index = torch.topk(next_token_prediction, 3).indices\n",
    "\n",
    "    target_token_id = target_token_indexes[0][idx].item()\n",
    "    pickup_token_indexes = [target_token_id] + next_token_prediction_top_k_index[0].tolist()\n",
    "    next_token_prediction_prob = next_token_prediction[0][pickup_token_indexes].tolist()\n",
    "    next_token_prediction_prob_text = [f'{token_id}: {prob:.3f}' for token_id, prob in zip(pickup_token_indexes, next_token_prediction_prob)]\n",
    "    next_token_prediction_prob = ', '.join(next_token_prediction_prob_text)\n",
    "    target_token_distribution = F.one_hot(target_token_indexes[0][idx], num_classes=vocab_size)[pickup_token_indexes].tolist()\n",
    "    target_token_distribution = [f'{token_id}: {prob}' for token_id, prob in zip(pickup_token_indexes, target_token_distribution)]\n",
    "    target_token_distribution = ', '.join(target_token_distribution)\n",
    "    print(template.format(input_text=input_text, input_token_id=input_token_id, token_embeddings=token_embeddings, next_token_prediction_prob=next_token_prediction_prob, target_prob=target_token_distribution))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 36724\n",
      "before training\n",
      "val_loss: 8.358726854722773\n",
      "start training\n",
      "epoch: 0, loss: 6.001175403594971, training_tokens: 320000\n",
      "epoch: 0, loss: 5.794539928436279, training_tokens: 640000\n",
      "epoch: 0, loss: 6.049036502838135, training_tokens: 960000\n",
      "epoch: 0, loss: 5.6892499923706055, training_tokens: 1280000\n",
      "epoch: 0, val_loss: 6.137528019963166\n"
     ]
    }
   ],
   "source": [
    "# Â≠¶Áøí\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nn_lm = BigramLanguageModel(vocab_size, d_model, d_ff).to(device)\n",
    "optimizer = torch.optim.AdamW(nn_lm.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 1\n",
    "training_tokens = 0\n",
    "print('before training')\n",
    "val_loss = 0\n",
    "for i in range(0, len(val_data_tokens), batch_size):\n",
    "    batch_tokens = val_data_tokens[i:i+batch_size]\n",
    "    input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "    target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "    with torch.no_grad():\n",
    "        loss = nn_lm.loss_per_token(input_token_indexes, target_token_indexes)\n",
    "    val_loss += loss.sum().item()\n",
    "val_loss = val_loss / len(val_data_tokens)\n",
    "print(f'val_loss: {val_loss}')\n",
    "print('start training')\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(mini_train_data_tokens), batch_size):\n",
    "        batch_tokens = mini_train_data_tokens[i:i+batch_size]\n",
    "        input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "        target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "        loss = nn_lm.loss(input_token_indexes, target_token_indexes)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_tokens += len(batch_tokens)\n",
    "        if training_tokens % 10000 == 0:\n",
    "            print(f'epoch: {epoch}, loss: {loss.item()}, training_tokens: {training_tokens}')\n",
    "    val_loss = 0\n",
    "    for i in range(0, len(val_data_tokens), batch_size):\n",
    "        batch_tokens = val_data_tokens[i:i+batch_size]\n",
    "        input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "        target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = nn_lm.loss_per_token(input_token_indexes, target_token_indexes)\n",
    "        val_loss += loss.sum().item()\n",
    "    val_loss = val_loss / len(val_data_tokens)\n",
    "    print(f'epoch: {epoch}, val_loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'„Äé'\n",
      "'Âãù'\n",
      "'„Å§'\n",
      "'„Åã'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n",
      "' '\n",
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "context = '„ÄéÂãù„Å§„Åã'\n",
    "context_token_indexes = torch.tensor(tokenizer.encode(context)).unsqueeze(0).to(device)\n",
    "generated_tokens = nn_lm.generate(context_token_indexes, max_new_tokens=20)\n",
    "for token in generated_tokens[0]:\n",
    "    print(repr(tokenizer.decode([token.item()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.028300762176514"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 512\n",
    "input_tokens = val_data_tokens[:context_length]\n",
    "target_tokens = val_data_tokens[1:context_length+1]\n",
    "input_token_indexes = torch.tensor(input_tokens).unsqueeze(0).to(device)\n",
    "target_token_indexes = torch.tensor(target_tokens).unsqueeze(0).to(device)\n",
    "nn_lm.loss(input_token_indexes, target_token_indexes).item()\n",
    "\n",
    "# bi-gram(„Éë„É©„É°„Éº„ÇøÊï∞ 16516096)„ÅÆÊÄßËÉΩ: 5.082467079162598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 4064\n",
      "8.309922989258318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(409.1455610444513, 7.38905609893065)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "# ÂΩì„Å¶„Åö„Å£„ÅΩ„ÅÜ„É¢„Éá„É´„ÅÆloss\n",
    "vocab_size = len(tokenizer.str_to_idx)\n",
    "print('vocab_size', vocab_size)\n",
    "print(-math.log(1/len(tokenizer.str_to_idx.values())))\n",
    "\n",
    "math.exp(6.014070987701416), math.exp(2.0) # Understanding Emergent Abilities of Language Models from the Loss Perspective, https://arxiv.org/abs/2403.15796"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÊºîÁøí1: MLP„ÅÆÂ±§„ÇíÂ¢ó„ÇÑ„Åó„Åü„Çä„ÄÅÂ≠¶ÁøíÁéá„Å™„Å©„ÇíÂ§âÊõ¥„Åó„Å¶Êú™Êù•„ÅÆÂçòË™û„ÅÆ‰∫àÊ∏¨Á≤æÂ∫¶Âêë‰∏ä„ÇíË©¶„Åø„Çã„ÄÅÈÅéÂéª„ÅÆN„Éà„Éº„ÇØ„É≥„ÇíÂÖ•Âäõ„Å®„Åô„Çã„É¢„Éá„É´„ÇíÊßãÁØâ„Åó„Å¶„Åø„Çà„ÅÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE ME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ë®ÄË™û„Éô„ÇØ„Éà„É´„Å®MLP„Å´„Çà„Çã„É¢„Éá„É´Âåñ„Å´„Çà„Å£„Å¶\n",
    "- ÂØÜ„Å™Ë®ÄË™û„Éô„ÇØ„Éà„É´Ë°®Áèæ„Å´„Çà„Å£„Å¶„ÄÅÂçòË™û„ÅÆÊÑèÂë≥„ÇÑÊ¶ÇÂøµ„ÇíË°®Áèæ\n",
    "- „Éë„É©„É°„Éº„ÇøÊï∞„ÅåO(exp(n))„Åã„ÇâO(n)„Å∏„Å®ÂâäÊ∏õ\n",
    "\n",
    "ÊÆã„ÇãË™≤È°å\n",
    "- Ë¶ã„Çå„ÇãÈÅéÂéª„ÅÆÊñáËÑàÈï∑„ÅåÂõ∫ÂÆö„ÄÅÂ¢ó„ÇÑ„Åù„ÅÜ„Å®„Åô„Çã„Å®„Éë„É©„É°„Éº„ÇøÊï∞„ÅåÂ¢óÂä†"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN„Å´„Çà„Çã„É¢„Éá„É´Âåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input [1, 3, 3, 1] ['„ÅÑ', '„Åà', '„Åà', '„ÅÑ']\n",
      "model target [3, 3, 1, 5] ['„Åà', '„Åà', '„ÅÑ', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab = {'„ÅÇ': 0, '„ÅÑ': 1, '„ÅÜ':2, '„Åà':3, '„Åä':4, '<|endoftext|>':5}\n",
    "idx_to_ch = dict((v, k) for (k,v) in vocab.items())\n",
    "text = '„ÅÑ„Åà„Åà„ÅÑ'\n",
    "text = list(text) + ['<|endoftext|>']\n",
    "text = [vocab[ch] for ch in text]\n",
    "model_input = torch.tensor(text[:-1])\n",
    "model_target = torch.tensor(text[1:])\n",
    "print('model input', model_input.tolist(), [idx_to_ch[idx] for idx in model_input.tolist()])\n",
    "print('model target', model_target.tolist(), [idx_to_ch[idx] for idx in model_target.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN„ÅÆÂÆöÁæ©\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 5\n",
    "hidden_dim = 3\n",
    "hidden_start = torch.zeros((1, hidden_dim)).T\n",
    "word_embedding_table = torch.randn((vocab_size, embedding_dim))\n",
    "\n",
    "We = torch.randn((hidden_dim, embedding_dim))\n",
    "Wh = torch.randn((hidden_dim, hidden_dim))\n",
    "Wy = torch.randn((vocab_size, hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['„ÅÑ'] ----> RNN ---->  „Åà\n",
      "P(„Åà | „ÅÑ) = 0.025\n",
      "[0.048, 0.178, 0.208, 0.025, 0.432, 0.109] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "['„ÅÑ', '„Åà'] ----> RNN ---->  „Åà\n",
      "P(„Åà | „ÅÑ, „Åà) = 0.220\n",
      "[0.409, 0.123, 0.051, 0.22, 0.096, 0.101] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "['„ÅÑ', '„Åà', '„Åà'] ----> RNN ---->  „ÅÑ\n",
      "P(„ÅÑ | „ÅÑ, „Åà, „Åà) = 0.137\n",
      "[0.091, 0.137, 0.122, 0.277, 0.148, 0.224] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "['„ÅÑ', '„Åà', '„Åà', '„ÅÑ'] ----> RNN ---->  <|endoftext|>\n",
      "P(<|endoftext|> | „ÅÑ, „Åà, „Åà, „ÅÑ) = 0.119\n",
      "[0.028, 0.163, 0.219, 0.023, 0.448, 0.119] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN„ÅÆÈ†Ü‰ºùÊí≠„ÅÆË®àÁÆó„ÅÆÊßòÂ≠ê\n",
    "h_t_minus_1 = hidden_start\n",
    "input_history = []\n",
    "\n",
    "# Ââç„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÅÆË®àÁÆó„ÅåÊ¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÅÆË®àÁÆó„Å´ÂΩ±Èüø„Åô„Çã„Åü„ÇÅ‰∏¶ÂàóÂåñ„ÅåÈõ£„Åó„ÅÑ„ÄÇ\n",
    "# RNN„ÅÆË®àÁÆóË§áÈõëÂ∫¶ len(model_input.tolist()) * hidden_dim * hidden_dim = T * d * d\n",
    "for t in range(len(model_input.tolist())):\n",
    "    idx = model_input.tolist()[t]\n",
    "    input_history.append(idx_to_ch[idx])\n",
    "    print(input_history, '----> RNN ----> ', idx_to_ch[model_target.tolist()[t]])\n",
    "    x = torch.LongTensor([idx])\n",
    "    x = word_embedding_table[x].T\n",
    "    # Attention„ÇíÂ∞éÂÖ•„Åó„Åü„ÅÑ„Éù„Ç§„É≥„Éà„ÄÅÈÅéÂéª„ÅÆÊñáËÑà„Ååh_t_minus_1„Å´Êäº„ÅóËæº„Åæ„Çå„Çã\n",
    "    # „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅåÂçòË™ûÊñπÂêë„Å´Ê∑±„Åè„Å™„Çã„Åü„ÇÅÂ≠¶Áøí„Åå‰∏çÂÆâÂÆö„Å´\n",
    "    # d * d, Á≥ªÂàóÈï∑„Å´„Çà„Çâ„Åö‰∏ÄÂÆö\n",
    "    h_t = torch.tanh(torch.matmul(We, x) + torch.matmul(Wh, h_t_minus_1))\n",
    "    logits = torch.matmul(Wy, h_t)\n",
    "    print(f'P({idx_to_ch[model_target.tolist()[t]]} | {\", \".join(input_history)}) = {torch.softmax(logits, dim=0).squeeze().tolist()[model_target.tolist()[t]]:.3f}')\n",
    "    model_target_onehot = torch.zeros((1, vocab_size))\n",
    "    model_target_onehot[0, model_target.tolist()[t]] = 1\n",
    "    h_t_minus_1 = h_t\n",
    "    output_dist = [float('{:.3f}'.format(output)) for output in torch.softmax(logits, dim=0).squeeze().tolist()]\n",
    "    print(f'{output_dist} <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> {model_target_onehot.tolist()[0]}')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN„Å´„Çà„Çã„É¢„Éá„É´Âåñ„Å´„Çà„Å£„Å¶\n",
    "- ÊñáËÑàÈï∑„ÇíÂõ∫ÂÆö„Åõ„Åö„Å´„ÄÅ‰ªªÊÑè„ÅÆÈï∑„Åï„ÅÆÊñáËÑà„ÇíËÄÉÊÖÆ\n",
    "- ÊñáËÑàÈï∑„ÅåÂ¢ó„Åà„Å¶„ÇÇ„Éë„É©„É°„Éº„ÇøÊï∞„ÅåÂ¢ó„Åà„Å™„ÅÑ\n",
    "\n",
    "ÊÆã„ÇãË™≤È°å\n",
    "- Â≠¶Áøí„Åå‰∏çÂÆâÂÆö(ÂãæÈÖçÊ∂àÂ§±„ÄÅÂãæÈÖçÁàÜÁô∫)\n",
    "- ‰∏¶ÂàóÂåñ„Åå„Åß„Åç„Åö„ÄÅÂ≠¶Áøí„ÅåÈÅÖ„ÅÑ\n",
    "- ÊñáËÑàÈï∑„ÅåÈï∑„Åè„Å™„Çã„Å®„Éà„Éº„ÇØ„É≥„ÅÆÈï∑Ë∑ùÈõ¢‰æùÂ≠òÈñ¢‰øÇ„ÅÆÊääÊè°„ÅåÈõ£„Åó„Åè„Å™„Çã„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÊºîÁøí2: RNN„ÅßÂ≠¶Áøí„ÄÅÁîüÊàê„Åó„Å¶„Åø„Çà„ÅÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE ME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer„Å´„Çà„Çã„É¢„Éá„É´Âåñ„Å®Â≠¶Áøí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention $(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V$\n",
    "\n",
    "Attention Is All You Need„ÅÆÂºè(1)„Çà„Çä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_length = 4\n",
    "d_head = 2\n",
    "\n",
    "K = torch.randn(batch_size, sequence_length, d_head)\n",
    "Q = torch.randn(batch_size, sequence_length, d_head)\n",
    "V = torch.randn(batch_size, sequence_length, d_head)\n",
    "\n",
    "qk_dot_product = Q @ K.transpose(-2, -1)\n",
    "scaled_qk_dot_product = qk_dot_product / (d_head ** 0.5)\n",
    "\n",
    "attention_scores = torch.softmax(scaled_qk_dot_product, dim=-1)\n",
    "attention_output = attention_scores @ V\n",
    "\n",
    "attention_scores_without_scale = torch.softmax(qk_dot_product, dim=-1)\n",
    "attention_output_without_scale = attention_scores_without_scale @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6550), tensor(0.3275))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_dot_product.var(), scaled_qk_dot_product.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1064, 0.2228, 0.2430, 0.4278]]), tensor(1.))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[:, -1, :], attention_scores[:, -1, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1064, 0.2228, 0.2430, 0.4278]]),\n",
       " tensor([[0.0704, 0.2000, 0.2262, 0.5034]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[:, -1, :], attention_scores_without_scale[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\operatorname{FFN}(x)=\\max \\left(0, x W_1+b_1\\right) W_2+b_2$  \n",
    "Attention Is All You Need„ÅÆÂºè(2)„Çà„Çä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# MLP„Åß„ÅÆÂÆüË£Ö„ÅÆÈöõ„Å´ÂÆüË£Ö\n",
    "self.ff = nn.Sequential(\n",
    "    nn.Linear(d_model, d_ff),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(d_ff, d_model)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embdding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 38597376\n",
      "positional embedding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 786432\n",
      "self-attention„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 28311552\n",
      "feed-forward„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 56623104\n",
      "ÂêàË®à„Éë„É©„É°„Éº„ÇøÊï∞ 124318464\n",
      "embedding„ÅÆÂâ≤Âêà 0.31047178961284466\n",
      "positional embedding„ÅÆÂâ≤Âêà 0.006325946884285829\n",
      "self-attention„ÅÆÂâ≤Âêà 0.22773408783428983\n",
      "feed-forward„ÅÆÂâ≤Âêà 0.45546817566857967\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPT-2 Small\n",
    "vocab_size = 50257\n",
    "d_model = embedding_dim = 768 \n",
    "d_ff = d_model * 4\n",
    "n_head = 12 \n",
    "n_layer = 12\n",
    "d_k = int(d_model / n_head)\n",
    "d_v = int(d_model / n_head)\n",
    "\n",
    "word_embedding_table = torch.randn((vocab_size, embedding_dim))\n",
    "\n",
    "Wq = torch.randn((d_k, embedding_dim))\n",
    "Wk = torch.randn((d_k, embedding_dim))\n",
    "\n",
    "Wv = torch.randn((d_v, embedding_dim))\n",
    "Wo = torch.randn((d_model, d_v * n_head))\n",
    "\n",
    "Wff_1 = torch.randn((d_ff, d_model))\n",
    "Wff_2 = torch.randn((d_model, d_ff))\n",
    "Wy = torch.randn((vocab_size, d_model))\n",
    "\n",
    "params_embedding = vocab_size * embedding_dim\n",
    "print('embdding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_embedding)\n",
    "\n",
    "params_positional_embedding = d_model * 1024\n",
    "print('positional embedding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_positional_embedding)\n",
    "\n",
    "params_self_attention = (d_model * d_k * n_head * 2 + d_model * d_v * n_head + d_model * d_v * n_head) * n_layer\n",
    "print('self-attention„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_self_attention)\n",
    "\n",
    "params_ff = (d_ff * d_model * 2) * n_layer\n",
    "print('feed-forward„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_ff)\n",
    "\n",
    "total_params = params_positional_embedding + params_embedding + params_self_attention + params_ff # + params_unembedding weight tied\n",
    "print('ÂêàË®à„Éë„É©„É°„Éº„ÇøÊï∞', total_params)\n",
    "\n",
    "# „Éë„É©„É°„Éº„ÇøÊï∞„ÅÆÂÜÖË®≥Ââ≤Âêà\n",
    "print('embedding„ÅÆÂâ≤Âêà', params_embedding / total_params)\n",
    "print('positional embedding„ÅÆÂâ≤Âêà', params_positional_embedding / total_params)\n",
    "print('self-attention„ÅÆÂâ≤Âêà', params_self_attention / total_params)\n",
    "print('feed-forward„ÅÆÂâ≤Âêà', params_ff / total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embdding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 18\n",
      "positional embedding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 3072\n",
      "self-attention„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 36\n",
      "feed-forward„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞ 72\n",
      "ÂêàË®à„Éë„É©„É°„Éº„ÇøÊï∞ 3198\n",
      "embedding„ÅÆÂâ≤Âêà 0.005628517823639775\n",
      "positional embedding„ÅÆÂâ≤Âêà 0.9606003752345216\n",
      "self-attention„ÅÆÂâ≤Âêà 0.01125703564727955\n",
      "feed-forward„ÅÆÂâ≤Âêà 0.0225140712945591\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1Â±§„ÅÆFF„Å®Attention„ÅÆ„Åø„ÅÆ„É¢„Éá„É´\n",
    "vocab_size = len(vocab)\n",
    "d_model = embedding_dim = 3\n",
    "d_ff = d_model * 4\n",
    "n_head = 1 \n",
    "n_layer = 1 \n",
    "d_k = int(d_model / n_head)\n",
    "d_v = int(d_model / n_head)\n",
    "\n",
    "word_embedding_table = torch.randn((vocab_size, embedding_dim))\n",
    "\n",
    "Wq = torch.randn((d_k, embedding_dim))\n",
    "Wk = torch.randn((d_k, embedding_dim))\n",
    "\n",
    "Wv = torch.randn((d_v, embedding_dim))\n",
    "Wo = torch.randn((d_model, d_v * n_head))\n",
    "\n",
    "Wff_1 = torch.randn((d_ff, d_model))\n",
    "Wff_2 = torch.randn((d_model, d_ff))\n",
    "Wy = torch.randn((vocab_size, d_model))\n",
    "\n",
    "params_embedding = vocab_size * embedding_dim\n",
    "print('embdding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_embedding)\n",
    "\n",
    "params_positional_embedding = d_model * 1024\n",
    "print('positional embedding„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_positional_embedding)\n",
    "\n",
    "params_self_attention = (d_model * d_k * n_head * 2 + d_model * d_v * n_head + d_model * d_v * n_head) * n_layer\n",
    "print('self-attention„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_self_attention)\n",
    "\n",
    "params_ff = (d_ff * d_model * 2) * n_layer\n",
    "print('feed-forward„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞', params_ff)\n",
    "\n",
    "total_params = params_positional_embedding + params_embedding + params_self_attention + params_ff # + params_unembedding weight tied\n",
    "print('ÂêàË®à„Éë„É©„É°„Éº„ÇøÊï∞', total_params)\n",
    "\n",
    "# „Éë„É©„É°„Éº„ÇøÊï∞„ÅÆÂÜÖË®≥Ââ≤Âêà\n",
    "print('embedding„ÅÆÂâ≤Âêà', params_embedding / total_params)\n",
    "print('positional embedding„ÅÆÂâ≤Âêà', params_positional_embedding / total_params)\n",
    "print('self-attention„ÅÆÂâ≤Âêà', params_self_attention / total_params)\n",
    "print('feed-forward„ÅÆÂâ≤Âêà', params_ff / total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(„Åà | „ÅÑ) = 0.000\n",
      "[0.01, 0.0, 0.989, 0.0, 0.001, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "P(„Åà | „ÅÑ, „Åà) = 0.000\n",
      "[0.003, 0.0, 0.997, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "P(„ÅÑ | „ÅÑ, „Åà, „Åà) = 0.000\n",
      "[0.002, 0.0, 0.998, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "P(<|endoftext|> | „ÅÑ, „Åà, „Åà, „ÅÑ) = 0.000\n",
      "[0.002, 0.0, 0.997, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‰∏¶ÂàóÂåñ„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑSelf-AttentionÂ±§„ÄÅFeedForwardÂ±§„ÅÆË®àÁÆó\n",
    "quries = []\n",
    "keys = []\n",
    "values = []\n",
    "attention_scores = []\n",
    "attention_outputs = []\n",
    "input_history = []\n",
    "\n",
    "# Self-Attention„ÅÆË®àÁÆóË§áÈõëÂ∫¶ len(model_input.tolist()) * len(model_input.tolist()) * d_model = T * T * d\n",
    "for t in range(len(model_input.tolist())):\n",
    "    idx = model_input.tolist()[t]\n",
    "    input_history.append(idx_to_ch[idx])\n",
    "    x = torch.LongTensor([idx])\n",
    "    x = word_embedding_table[x].T # + positional_encodings\n",
    "    \n",
    "    # single-head, multi-head„Å´„Å™„Çã„Å®Ë§áÊï∞„ÅÆË¶≥ÁÇπ„Åßquery, key, value„ÅÆÁô∫Ë°å„Çí„Åô„Çã\n",
    "    query_t = torch.matmul(Wq, x) # „Äá„ÄáÊé¢„Åó„Å¶„Åæ„ÅôÔºÅ ‰æã: token_0: Ëá™ÂàÜ‰∏ªË™û„Åß„Åô„ÄÅÁõÆÁöÑË™û„Å®„ÅãÂä©Ë©û„Å®„ÅãÂãïË©û„Å®„ÅãÊé¢„Åó„Å¶„Åæ„ÅôÔºÅ\n",
    "\n",
    "    key_t = torch.matmul(Wk, x) # „Äá„ÄáÊåÅ„Å£„Å¶„Åæ„ÅôÔºÅ ‰æã: token_0: Ëá™ÂàÜ‰∏ªË™û„Åß„ÅôÔºÅ token_1: Ëá™ÂàÜÂãïË©û„Åß„Åô!\n",
    "    value_t = torch.matmul(Wv, x) # ‰∏≠Ë∫´„ÅÆË©≥Á¥∞„Åß„ÅôÔºÅ ‰æã: token_0: „ÄåÊãôËÄÖ„Äç„Åß„Åô„ÄÅÁèç„Åó„ÅÑ1‰∫∫Áß∞„Åß„Åô„ÄÅ„Åä‰æç„Åï„Çì„Å®„Åã„Åå‰Ωø„Å£„Åü„Çä„Åó„Åæ„Åô token_1: „ÄåÈ£ü„Åπ„Çã„Äç„Åß„Åô„ÄÅÈ£ü„ÅπÁâ©„ÇíÂè£„Å´ÂÖ•„Çå„ÇãË°åÁÇ∫„Åß„Åô\n",
    "    \n",
    "    # cross attention„ÅÆÂ†¥Âêà„ÅØkey, value„ÅØ\n",
    "    # key_t = torch.matmul(Wk, another_modality_x)\n",
    "    # value_t = torch.matmul(Wv, another_modality_x)„ÅÆ„Çà„ÅÜ„Å´„Å™„Çã\n",
    "\n",
    "    quries.append(query_t)\n",
    "    keys.append(key_t)\n",
    "    values.append(value_t)\n",
    "    # Day2„ÅÆÊºîÁøí„Åß„ÅØÊñáÁ´†Âçò‰Ωç„Åß„Éô„ÇØ„Éà„É´Âåñ„Åó„Åüquery„Å®key„ÅÆÂÜÖÁ©ç(È°û‰ººÂ∫¶)„Çí„ÇÇ„Å®„Å´Retrieval„ÇíË°å„Å£„Åü\n",
    "    # Ë®àÁÆóË§áÈõëÂ∫¶ T * d„ÄÅÁ≥ªÂàóÈï∑„Å´„Çà„Å£„Å¶Â§âÂåñ\n",
    "    # ÈÅ†„ÅèÈõ¢„Çå„ÅüÈÅéÂéª„ÅÆÊñáËÑà„ÇíËÄÉÊÖÆ„Åß„Åç„Çã„ÄÅÂÖ•Âäõ„Éá„Éº„Çø„Å´Âøú„Åò„Å¶Áõ∏‰∫í‰ΩúÁî®„Åó„ÄÅ„Åù„ÅÆÁµêÊûú„ÅåÂæå„ÅÆÊ∑±„ÅÑÂ±§„Åß„ÇÇÂèçÊò†„Åï„Çå„Çã\n",
    "    attention_score = torch.matmul(query_t.T, torch.stack(keys)) / torch.sqrt(torch.tensor(d_k))\n",
    "    attention_score = torch.softmax(attention_score, dim=0)\n",
    "    attention_scores.append(attention_score.squeeze())\n",
    "    self_attention_output = 0\n",
    "    for i in range(len(attention_score)):\n",
    "        # query„ÄÅkey„ÅÆ„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÁµêÊûú„Ååvalue„Å´ÂèçÊò†„Åï„Çå„Çã(attention score„ÅßÈáç„Åø‰ªò„Åë)\n",
    "        self_attention_output += attention_score[i] * values[i]\n",
    "    attention_outputs.append(self_attention_output)\n",
    "\n",
    "    # FeedForward„ÅÆË®àÁÆó\n",
    "    ff_output = torch.matmul(Wff_2, torch.relu(torch.matmul(Wff_1, self_attention_output)))\n",
    "    # Ê¨°ÂçòË™û‰∫àÊ∏¨„ÄÅ„Çø„Çπ„ÇØÁâπÂåñ„ÅÆ„Åü„ÇÅ„ÅÆÂàÜÈ°ûÂô®„Çí‰Ωú„Çã„Çà„ÅÜ„Å™Â†¥Âêà„Å´„ÅØÊñ∞„Åó„ÅèWy„ÇíÁî®ÊÑè„Åó„Å¶Â≠¶Áøí„Åô„Çã\n",
    "    logits = torch.matmul(Wy, ff_output)\n",
    "    output_dist = [float('{:.3f}'.format(output)) for output in torch.softmax(logits, dim=0).squeeze().tolist()]\n",
    "    \n",
    "    print(f'P({idx_to_ch[model_target.tolist()[t]]} | {\", \".join(input_history)}) = {torch.softmax(logits, dim=0).squeeze().tolist()[model_target.tolist()[t]]:.3f}')\n",
    "    model_target_onehot = torch.zeros((1, vocab_size))\n",
    "    model_target_onehot[0, model_target.tolist()[t]] = 1\n",
    "    print(f'{output_dist} <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> {model_target_onehot.tolist()[0]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ['„ÅÑ', '„Åà', '„Åà', '„ÅÑ']\n",
      "„ÅÑ [1.0, 0.0, 0.0, 0.0]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "token ['„ÅÑ', '„Åà', '„Åà', '„ÅÑ']\n",
      "„Åà [0.43965405225753784, 0.5603459477424622, 0.0, 0.0]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "token ['„ÅÑ', '„Åà', '„Åà', '„ÅÑ']\n",
      "„Åà [0.2817670404911041, 0.35911649465560913, 0.35911649465560913, 0.0]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "token ['„ÅÑ', '„Åà', '„Åà', '„ÅÑ']\n",
      "„ÅÑ [0.20397628843784332, 0.29602372646331787, 0.29602372646331787, 0.20397628843784332]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# attention„ÅÆÂèØË¶ñÂåñ\n",
    "attention_map = torch.zeros((len(model_input.tolist()), len(model_input.tolist())))\n",
    "for t in range(len(model_input.tolist())):\n",
    "    attention_map[t][:t+1] = attention_scores[t]\n",
    "    print('token', input_history)\n",
    "    print(input_history[t], attention_map[t].tolist())\n",
    "    print('-----' * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(„Åà | „ÅÑ) = 0.000\n",
      "[0.01, 0.0, 0.989, 0.0, 0.001, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "P(„Åà | „ÅÑ, „Åà) = 0.000\n",
      "[0.003, 0.0, 0.997, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "P(„ÅÑ | „ÅÑ, „Åà, „Åà) = 0.000\n",
      "[0.002, 0.0, 0.998, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "P(<|endoftext|> | „ÅÑ, „Åà, „Åà, „ÅÑ) = 0.000\n",
      "[0.002, 0.0, 0.997, 0.0, 0.0, 0.0] <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Êú™Êù•„ÅÆÊÉÖÂ†±„ÇíÁî®„ÅÑ„Å™„ÅÑ„Çà„ÅÜ„Å´Causal Attention„ÇíÁî®„ÅÑ„Å¶‰∏¶ÂàóÂåñ(Ë°åÂàó„ÅÆË®àÁÆó„Å´„Åô„Çã)\n",
    "input_ids = model_input.tolist()\n",
    "x = torch.LongTensor([input_ids])\n",
    "x = word_embedding_table[x] # + positional_encodings\n",
    "# print(x.shape) # (1, T, embedding_dim)\n",
    "\n",
    "queries = torch.matmul(x.squeeze(), Wq.T) # (T, d_k)\n",
    "keys = torch.matmul(x.squeeze(), Wk.T) # (T, d_k)\n",
    "values = torch.matmul(x.squeeze(), Wv.T) # (T, d_v)\n",
    "# print(queries.shape, keys.shape, values.shape)\n",
    "\n",
    "attention_scores = torch.matmul(queries, keys.T) / torch.sqrt(torch.tensor(d_k)) # (T, T)\n",
    "# causal attention„ÄÅÊú™Êù•„ÅÆÊÉÖÂ†±„ÇíÁî®„ÅÑ„Å™„ÅÑ„Çà„ÅÜ„Å´„Åô„Çã\n",
    "attention_mask = torch.tril(torch.ones((len(model_input.tolist()), len(model_input.tolist())))) # (T, T)\n",
    "attention_scores = attention_scores.masked_fill(attention_mask==0, float('-inf'))\n",
    "\n",
    "attention_scores = torch.softmax(attention_scores, dim=1) # (T, T)\n",
    "attention_outputs = torch.matmul(attention_scores, values) # (T, d_v)\n",
    "\n",
    "# FeedForward„ÅÆË®àÁÆó\n",
    "ff_output = torch.matmul(torch.relu(torch.matmul(attention_outputs, Wff_1.T)), Wff_2.T) # (T, d_model)\n",
    "# print(ff_output.shape)\n",
    "# Ê¨°ÂçòË™û‰∫àÊ∏¨\n",
    "logits = torch.matmul(ff_output, Wy.T) # (T, vocab_size)\n",
    "output_dists = torch.softmax(logits, dim=1) # (T, vocab_size)\n",
    "\n",
    "for step_t, output_dist in enumerate(output_dists):\n",
    "    print(f'P({idx_to_ch[model_target.tolist()[step_t]]} | {\", \".join(input_history[:step_t + 1])}) = {output_dist[model_target.tolist()[step_t]]:.3f}')\n",
    "    model_target_onehot = torch.zeros((1, vocab_size))\n",
    "    model_target_onehot[0, model_target.tolist()[step_t]] = 1\n",
    "    print(f'{[float(\"{:.3f}\".format(output)) for output in output_dist.tolist()]} <-----Â≠¶Áøí„Å´„Çà„Å£„Å¶Ëøë„Å•„Åë„Çã-----> {model_target_onehot.tolist()[0]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal attentionÂâç\n",
      "tensor([[ 0.6740,  1.0464,  1.0464,  0.6740],\n",
      "        [-0.4587, -0.2161, -0.2161, -0.4587],\n",
      "        [-0.4587, -0.2161, -0.2161, -0.4587],\n",
      "        [ 0.6740,  1.0464,  1.0464,  0.6740]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n",
      "causal attentionÂæå\n",
      "tensor([[ 0.6740,    -inf,    -inf,    -inf],\n",
      "        [-0.4587, -0.2161,    -inf,    -inf],\n",
      "        [-0.4587, -0.2161, -0.2161,    -inf],\n",
      "        [ 0.6740,  1.0464,  1.0464,  0.6740]])\n",
      "softmaxÂæå\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4397, 0.5603, 0.0000, 0.0000],\n",
      "        [0.2818, 0.3591, 0.3591, 0.0000],\n",
      "        [0.2040, 0.2960, 0.2960, 0.2040]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = torch.matmul(queries, keys.T) / torch.sqrt(torch.tensor(d_k)) # (T, T)\n",
    "print('causal attentionÂâç')\n",
    "print(attention_scores)\n",
    "# causal attention„ÅÆÂ†¥Âêà„ÅØattention_mask„ÇíÁî®„ÅÑ„Å¶Êú™Êù•„ÅÆÊÉÖÂ†±„Çí„Éû„Çπ„ÇØ„Åô„Çã\n",
    "attention_mask = torch.tril(torch.ones((len(model_input.tolist()), len(model_input.tolist())))) # (T, T)\n",
    "# ‰∏ã‰∏âËßíË°åÂàó„ÅßÊú™Êù•„ÅÆÊÉÖÂ†±„Çí„Éû„Çπ„ÇØ\n",
    "print(attention_mask)\n",
    "# Êú™Êù•„ÅÆÊÉÖÂ†±„ÅØscore„Åå0„Å´„Å™„Çã„Çà„ÅÜ„Å´-inf„Çí‰ª£ÂÖ•(softmax„Åß0„Å´„Å™„Çã)\n",
    "attention_scores = attention_scores.masked_fill(attention_mask==0, float('-inf'))\n",
    "print('causal attentionÂæå')\n",
    "print(attention_scores)\n",
    "attention_scores = torch.softmax(attention_scores, dim=1) # (T, T)\n",
    "print('softmaxÂæå')\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, d_model, d_head):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(d_model, d_head, bias=False)\n",
    "        self.query = nn.Linear(d_model, d_head, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_head, bias=False)\n",
    "        self.back_to_d_model = nn.Linear(d_head, d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, sequence_length, d_model)\n",
    "        B, T, d_model = x.size()\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        qk_dot_product = q @ k.transpose(-2, -1) / (d_head ** 0.5)\n",
    "        mask = torch.tril(torch.ones((T, T))).to(qk_dot_product.device)\n",
    "        qk_dot_product = qk_dot_product.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_score = torch.softmax(qk_dot_product, dim=-1)\n",
    "        out = attention_score @ v\n",
    "        out = self.back_to_d_model(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionLM(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, d_model, d_head):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(sequence_length, d_model)\n",
    "        self.head = Head(d_model, d_head)\n",
    "        self.unembed = nn.Linear(d_model, vocab_size)\n",
    "        print('number of parameters:', sum(p.numel() for p in self.parameters()))\n",
    "    \n",
    "    \n",
    "    def forward(self, token_indexes):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        B, T = token_indexes.size()\n",
    "        token_embed = self.embed(token_indexes)\n",
    "        pos_embed = self.pos_embed(torch.arange(T).to(token_embed.device))\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.head(x)\n",
    "        logits = self.unembed(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def loss_per_token(self, token_indexes, targets):\n",
    "        logits = self(token_indexes)\n",
    "        # logits: (batch_size, sequence_length, vocab_size)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length, vocab_size = logits.shape\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(batch_size*sequence_length, vocab_size),\n",
    "            targets.view(batch_size*sequence_length),\n",
    "            reduction='none'\n",
    "            )\n",
    "        # loss: (batch_size*sequence_length)\n",
    "        return loss.view(batch_size, sequence_length)\n",
    "    \n",
    "    def loss(self, token_indexes, targets):\n",
    "        logits = self(token_indexes)\n",
    "        # logits: (batch_size, sequence_length, vocab_size)\n",
    "        # targets: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length, vocab_size = logits.shape\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(batch_size*sequence_length, vocab_size),\n",
    "            targets.view(batch_size*sequence_length)\n",
    "            )\n",
    "        # loss: scalar\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, token_indexes, max_new_tokens):\n",
    "        # token_indexes: (batch_size, sequence_length)\n",
    "        batch_size, sequence_length = token_indexes.shape\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(token_indexes)\n",
    "            # logits: (batch_size, sequence_length, vocab_size)\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            # next_token_logits: (batch_size, vocab_size)\n",
    "            next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
    "            # next_token_probs: (batch_size, vocab_size)\n",
    "            next_token = torch.multinomial(next_token_probs, num_samples=1)\n",
    "            # next_token: (batch_size, 1)\n",
    "            token_indexes = torch.cat([token_indexes, next_token], dim=1)\n",
    "            # token_indexes: (batch_size, sequence_length+1)\n",
    "        return token_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 38692\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vocab_size = len(tokenizer.str_to_idx)\n",
    "d_model = 4\n",
    "d_head = 4\n",
    "sequence_length = 512\n",
    "attention_lm = AttentionLM(vocab_size, sequence_length, d_model, d_head).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train_data_tokens = []\n",
    "mini_train_data_file_num = 1000\n",
    "mini_train_data_text = \"\"\n",
    "file_count = 0\n",
    "\n",
    "with gzip.open('train_9.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        mini_train_data_tokens += tokenizer.encode(data['text'], eot=True)\n",
    "        file_count += 1\n",
    "        if file_count == mini_train_data_file_num:\n",
    "            break\n",
    "\n",
    "val_data_tokens = []\n",
    "val_data_file_num = 1\n",
    "val_data_text = \"\"\n",
    "file_count = 0\n",
    "with gzip.open('validation_0.jsonl.gz', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # ÂêÑË°å„ÇíJSON„Å®„Åó„Å¶Ë™≠„ÅøËæº„ÇÄ\n",
    "        data = json.loads(line)\n",
    "        val_data_tokens += tokenizer.encode(data['text'], eot=True)\n",
    "        file_count += 1\n",
    "        if file_count == val_data_file_num:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "val_loss: 8.342648007167377\n",
      "start training\n",
      "epoch: 0, loss: 6.0860748291015625, training_tokens: 513000\n",
      "epoch: 0, loss: 5.641589164733887, training_tokens: 1026000\n",
      "epoch: 0, loss: 5.4656662940979, training_tokens: 1539000\n",
      "epoch: 0, val_loss: 6.292435605969679\n"
     ]
    }
   ],
   "source": [
    "# Â≠¶Áøí\n",
    "optimizer = torch.optim.AdamW(attention_lm.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "training_tokens = 0\n",
    "print('before training')\n",
    "val_loss = 0\n",
    "for i in range(0, len(val_data_tokens), sequence_length+1):\n",
    "    batch_tokens = val_data_tokens[i:i+sequence_length+1]\n",
    "    input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "    target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "    with torch.no_grad():\n",
    "        loss = attention_lm.loss_per_token(input_token_indexes, target_token_indexes)\n",
    "    val_loss += loss.sum().item()\n",
    "val_loss = val_loss / len(val_data_tokens)\n",
    "print(f'val_loss: {val_loss}')\n",
    "print('start training')\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(mini_train_data_tokens), sequence_length+1):\n",
    "        batch_tokens = mini_train_data_tokens[i:i+sequence_length+1]\n",
    "        input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "        target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "        loss = attention_lm.loss(input_token_indexes, target_token_indexes)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_tokens += len(batch_tokens)\n",
    "        if training_tokens % ((sequence_length+1)*1000) == 0:\n",
    "            print(f'epoch: {epoch}, loss: {loss.item()}, training_tokens: {training_tokens}')\n",
    "    val_loss = 0\n",
    "    for i in range(0, len(val_data_tokens), sequence_length+1):\n",
    "        batch_tokens = val_data_tokens[i:i+sequence_length+1]\n",
    "        input_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, :-1].to(device)\n",
    "        target_token_indexes = torch.tensor(batch_tokens).unsqueeze(0)[:, 1:].to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = attention_lm.loss_per_token(input_token_indexes, target_token_indexes)\n",
    "        val_loss += loss.sum().item()\n",
    "    val_loss = val_loss / len(val_data_tokens)\n",
    "    print(f'epoch: {epoch}, val_loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.738327980041504"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 512\n",
    "input_tokens =  mini_train_data_tokens[:context_length]\n",
    "target_tokens = mini_train_data_tokens[1:context_length+1]\n",
    "input_token_indexes = torch.tensor(input_tokens).unsqueeze(0).to(device)\n",
    "target_token_indexes = torch.tensor(target_tokens).unsqueeze(0).to(device)\n",
    "attention_lm.loss(input_token_indexes, target_token_indexes).item()\n",
    "\n",
    "# bi-gram(„Éë„É©„É°„Éº„ÇøÊï∞ 16516096)„ÅÆÊÄßËÉΩ: 5.082467079162598"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰∏äË®ò„ÅÆÂÆüË£Ö„Å´Âä†„Åà„ÄÅÂ≠¶Áøí„ÅÆÂÆâÂÆöÂåñ„ÅÆ„Åü„ÇÅ„Å´Residual Connection„Å®Layer Normalization„ÇíËøΩÂä†„Åô„Çã„Åì„Å®„ÅßTransformer„ÅÆblock„ÇíÂÆüË£Ö„Åß„Åç„Åæ„Åô„ÄÇ\n",
    "‰ª•‰∏ã„Å´GPT-2„ÅÆÂÆüË£Ö„Å®Â≠¶Áøí„ÅÆ„Ç≥„Éº„Éâ„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2„ÅÆÂÆüË£Ö code from https://github.com/karpathy/makemore/tree/master\n",
    "# https://github.com/karpathy/makemore/blob/master/makemore.py\n",
    "\"\"\"\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 Andrej Karpathy\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    block_size: int = None # length of the input sequences of integers\n",
    "    vocab_size: int = None # the input integers are in range [0 .. vocab_size -1]\n",
    "    # parameters below control the sizes of each model slightly differently\n",
    "    n_layer: int = 4\n",
    "    n_embd: int = 64\n",
    "    n_embd2: int = 64\n",
    "    n_head: int = 4\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Transformer Language Model (*exactly* as used in GPT-2)\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
    "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" an unassuming Transformer block \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            act     = NewGELU(),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.c_proj(m.act(m.c_fc(x))) # MLP forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        # residual connection\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        # residual connection\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\" Transformer Language Model, exactly as seen in GPT-2 \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.block_size = config.block_size\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # report number of parameters (note we don't count the decoder parameters in lm_head)\n",
    "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
    "        print(\"„Éà„É©„É≥„Çπ„Éï„Ç©„Éº„Éû„Éº„ÅÆ„Éë„É©„É°„Éº„Çø„ÉºÊï∞: %.2fM\" % (n_params/1e6,))\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.block_size\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÊºîÁøí3: Transformer„ÅÆ„É¢„Éá„É´ÊßãÈÄ†„ÇíÂ§âÊõ¥„Åó„Å¶ÊÄßËÉΩÂêë‰∏ä„ÇíË©¶„Åø„Çã"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÂèÇËÄÉ\n",
    "- [Andrej Karpathy(ÂÖÉTesla„ÅÆAI„ÉÅ„Éº„É†„ÅÆ„É™„Éº„ÉÄ„Éº„ÄÅOpenAI„ÅÆÂÖ±ÂêåÂâµÊ•≠ËÄÖ)„Å´„Çà„ÇãGPT-2ÂÆüË£Ö„Åæ„Åß„ÅÆË¨õÁæ©ÂãïÁîª](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
    "- [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)  \n",
    "- [CS224N: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)\n",
    "    - https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture08-transformers.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
