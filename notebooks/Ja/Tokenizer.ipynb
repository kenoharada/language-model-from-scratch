{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character base tokenizer \n",
    "å¸¸ç”¨æ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã€è¨˜å·ã‚’1æ–‡å­—å˜ä½ã§tokenizeã™ã‚‹tokenizerã‚’ä½œæˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.bunka.go.jp/kokugo_nihongo/sisaku/joho/joho/kijun/naikaku/kanji/joyokanjisakuin/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html PUBLIC \"-//W3C//Dtd XHTML 1.0 Transitional//EN\" \"http://www.w3.org/tr/xhtml1/Dtd/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"ja\"><!-- InstanceBegin template=\"/Templates/bottom.dwt\" codeOutsideHTMLIsLocked=\"false\" -->\\n<head>\\n<meta http-equiv=\"Content-'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "with open(\"index.html\", encoding=\"cp932\") as f:\n",
    "    html = f.read()\n",
    "html[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table id=\"urlist\" class=\"display\" border=\"1\" cellspacing=\"0\"\n",
       "summary=\"kanji\" cellpadding=\"2\" width=\"100%\">\n",
       "  <thead>\n",
       "  <tr>\n",
       "    <th bgcolor=\"#cc9999\">æ¼¢å­—</th>\n",
       "    <th bgcolor=\"#cc9999\">éŸ³è¨“</th>\n",
       "    <th bgcolor=\"#cc9999\">ä¾‹</th>\n",
       "    <th bgcolor=\"#cc9999\">å‚™è€ƒ</th>\n",
       "  </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "\n",
       "<tr><td><font size=\"7\">äºœ</font><font size=\"6\">ï¼ˆäºï¼‰</font></td><td>ã‚¢</td><td>äºœæµï¼Œäºœéº»ï¼Œäºœç†±å¸¯</td><td>ã€€</td></tr>\n",
       "<tr><td><font size=\"7\">å“€</font></td><td>ã‚¢ã‚¤ã€€<br />ã‚ã‚ã‚Œã€€<br />ã‚ã‚ã‚Œã‚€</td><td>å“€æ„ï¼Œå“€é¡˜ï¼Œæ‚²å“€<br />å“€ã‚Œï¼Œå“€ã‚Œãªè©±ï¼Œå“€ã‚ŒãŒã‚‹<br />å“€ã‚Œã‚€ï¼Œå“€ã‚Œã¿</td><td>ã€€</td></tr>\n",
       "<tr><td><font size=\"7\">æŒ¨</font></td><td>ã‚¢ã‚¤</td><td>æŒ¨æ‹¶</td><td>ã€€</td></tr>\n",
       "<tr><td><font size=\"7\">æ„›</font></td><td>ã‚¢ã‚¤</td><td>æ„›æƒ…ï¼Œæ„›èª­ï¼Œæ‹æ„›</td><td>æ„›åª›ï¼ˆãˆã²ã‚ï¼‰çœŒ</td></tr>  \n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "table_sample = '''\n",
    "<table id=\"urlist\" class=\"display\" border=\"1\" cellspacing=\"0\"\n",
    "summary=\"kanji\" cellpadding=\"2\" width=\"100%\">\n",
    "  <thead>\n",
    "  <tr>\n",
    "    <th bgcolor=\"#cc9999\">æ¼¢å­—</th>\n",
    "    <th bgcolor=\"#cc9999\">éŸ³è¨“</th>\n",
    "    <th bgcolor=\"#cc9999\">ä¾‹</th>\n",
    "    <th bgcolor=\"#cc9999\">å‚™è€ƒ</th>\n",
    "  </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "\n",
    "<tr><td><font size=\"7\">äºœ</font><font size=\"6\">ï¼ˆäºï¼‰</font></td><td>ã‚¢</td><td>äºœæµï¼Œäºœéº»ï¼Œäºœç†±å¸¯</td><td>ã€€</td></tr>\n",
    "<tr><td><font size=\"7\">å“€</font></td><td>ã‚¢ã‚¤ã€€<br />ã‚ã‚ã‚Œã€€<br />ã‚ã‚ã‚Œã‚€</td><td>å“€æ„ï¼Œå“€é¡˜ï¼Œæ‚²å“€<br />å“€ã‚Œï¼Œå“€ã‚Œãªè©±ï¼Œå“€ã‚ŒãŒã‚‹<br />å“€ã‚Œã‚€ï¼Œå“€ã‚Œã¿</td><td>ã€€</td></tr>\n",
    "<tr><td><font size=\"7\">æŒ¨</font></td><td>ã‚¢ã‚¤</td><td>æŒ¨æ‹¶</td><td>ã€€</td></tr>\n",
    "<tr><td><font size=\"7\">æ„›</font></td><td>ã‚¢ã‚¤</td><td>æ„›æƒ…ï¼Œæ„›èª­ï¼Œæ‹æ„›</td><td>æ„›åª›ï¼ˆãˆã²ã‚ï¼‰çœŒ</td></tr>  \n",
    "  </tbody>\n",
    "</table>\n",
    "'''\n",
    "HTML(table_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "joyo_kanji_info = dict()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.find(\"table\", id=\"urlist\")\n",
    "\n",
    "for row in table.find_all(\"tr\"):\n",
    "    if row.th:\n",
    "        continue\n",
    "    cols = row.find_all(\"td\")\n",
    "    kanji = cols[0].find(\"font\").text\n",
    "    on_kun = cols[1].text\n",
    "    examples = cols[2].text\n",
    "    note = cols[3].text\n",
    "    joyo_kanji_info[kanji] = {\"éŸ³è¨“\": on_kun, \"ä¾‹\": examples, \"å‚™è€ƒ\": note}\n",
    "print(len(joyo_kanji_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'äºœå“€æŒ¨æ„›æ›–æ‚ªæ¡åœ§æ‰±å®›'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(list(joyo_kanji_info.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "0123456789\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "' \\t\\n\\r\\x0b\\x0c'\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ\n",
    "print(string.ascii_letters)\n",
    "# æ•°å­—\n",
    "print(string.digits)\n",
    "# å¥èª­ç‚¹\n",
    "print(string.punctuation)\n",
    "# æ”¹è¡Œãªã©ç©ºç™½æ–‡å­—\n",
    "print(repr(string.whitespace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãã‚ãƒã„ã…ã†ã‡ãˆã‰ãŠã‹ãŒããããã‘ã’ã“ã”ã•ã–ã—ã˜ã™ãšã›ãœãããŸã ã¡ã¢ã£ã¤ã¥ã¦ã§ã¨ã©ãªã«ã¬ã­ã®ã¯ã°ã±ã²ã³ã´ãµã¶ã·ã¸ã¹ãºã»ã¼ã½ã¾ã¿ã‚€ã‚ã‚‚ã‚ƒã‚„ã‚…ã‚†ã‚‡ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚ã‚ã‚‘ã‚’ã‚“ã‚”ã‚•ã‚–ã‚—ã‚˜ã‚™ã‚šã‚›ã‚œã‚ã‚\n",
      "ã‚¡ã‚¢ã‚£ã‚¤ã‚¥ã‚¦ã‚§ã‚¨ã‚©ã‚ªã‚«ã‚¬ã‚­ã‚®ã‚¯ã‚°ã‚±ã‚²ã‚³ã‚´ã‚µã‚¶ã‚·ã‚¸ã‚¹ã‚ºã‚»ã‚¼ã‚½ã‚¾ã‚¿ãƒ€ãƒãƒ‚ãƒƒãƒ„ãƒ…ãƒ†ãƒ‡ãƒˆãƒ‰ãƒŠãƒ‹ãƒŒãƒãƒãƒãƒãƒ‘ãƒ’ãƒ“ãƒ”ãƒ•ãƒ–ãƒ—ãƒ˜ãƒ™ãƒšãƒ›ãƒœãƒãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ£ãƒ¤ãƒ¥ãƒ¦ãƒ§ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ®ãƒ¯ãƒ°ãƒ±ãƒ²ãƒ³ãƒ´ãƒµãƒ¶ãƒ·ãƒ¸ãƒ¹ãƒºãƒ»ãƒ¼ãƒ½ãƒ¾\n",
      "ã€€ã€ã€‚ã€ƒã€„ã€…ã€†ã€‡ã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘ã€’ã€“ã€”ã€•ã€–ã€—ã€˜ã€™ã€šã€›ã€œã€ã€ã€Ÿã€ ã€¡ã€¢ã€£ã€¤ã€¥ã€¦ã€§ã€¨ã€©ã€ªã€«ã€¬ã€­ã€®ã€¯ã€°ã€±ã€²ã€³ã€´ã€µã€¶ã€·ã€¸ã€¹ã€ºã€»ã€¼ã€½ã€¾\n",
      "ï¼€ï¼ï¼‚ï¼ƒï¼„ï¼…ï¼†ï¼‡ï¼ˆï¼‰ï¼Šï¼‹ï¼Œï¼ï¼ï¼ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼šï¼›ï¼œï¼ï¼ï¼Ÿï¼ ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï¼»ï¼¼ï¼½ï¼¾ï¼¿ï½€ï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï½›ï½œï½ï½ï½Ÿï½ ï½¡ï½¢ï½£ï½¤ï½¥ï½¦ï½§ï½¨ï½©ï½ªï½«ï½¬ï½­ï½®ï½¯ï½°ï½±ï½²ï½³ï½´ï½µï½¶ï½·ï½¸ï½¹ï½ºï½»ï½¼ï½½ï½¾ï½¿ï¾€ï¾ï¾‚ï¾ƒï¾„ï¾…ï¾†ï¾‡ï¾ˆï¾‰ï¾Šï¾‹ï¾Œï¾ï¾ï¾ï¾ï¾‘ï¾’ï¾“ï¾”ï¾•ï¾–ï¾—ï¾˜ï¾™ï¾šï¾›ï¾œï¾ï¾ï¾Ÿï¾ ï¾¡ï¾¢ï¾£ï¾¤ï¾¥ï¾¦ï¾§ï¾¨ï¾©ï¾ªï¾«ï¾¬ï¾­ï¾®ï¾¯ï¾°ï¾±ï¾²ï¾³ï¾´ï¾µï¾¶ï¾·ï¾¸ï¾¹ï¾ºï¾»ï¾¼ï¾½ï¾¾ï¾¿ï¿€ï¿ï¿‚ï¿ƒï¿„ï¿…ï¿†ï¿‡ï¿ˆï¿‰ï¿Šï¿‹ï¿Œï¿ï¿ï¿ï¿ï¿‘ï¿’ï¿“ï¿”ï¿•ï¿–ï¿—ï¿˜ï¿™ï¿šï¿›ï¿œï¿ï¿ï¿Ÿï¿ ï¿¡ï¿¢ï¿£ï¿¤ï¿¥ï¿¦ï¿§ï¿¨ï¿©ï¿ªï¿«ï¿¬ï¿­ï¿®\n"
     ]
    }
   ],
   "source": [
    "# https://www.unicode.org/charts/nameslist/\n",
    "# ã²ã‚‰ãŒãª\n",
    "start = 0x3041\n",
    "end = 0x309F\n",
    "hiragana = \"\".join(chr(i) for i in range(start, end))\n",
    "print(hiragana)\n",
    "\n",
    "# ã‚«ã‚¿ã‚«ãƒŠ\n",
    "start = 0x30A1\n",
    "end = 0x30FF\n",
    "katakana = \"\".join(chr(i) for i in range(start, end))\n",
    "print(katakana)\n",
    "\n",
    "# CJK Symbols and Punctuation\n",
    "start = 0x3000\n",
    "end = 0x303F\n",
    "cjk_symbols_punctuation = \"\".join(chr(i) for i in range(start, end))\n",
    "print(cjk_symbols_punctuation)\n",
    "\n",
    "# Halfwidth and Fullwidth Forms\n",
    "start = 0xFF00\n",
    "end = 0xFFEF\n",
    "halfwidth_fullwidth_forms = \"\".join(chr(i) for i in range(start, end))\n",
    "print(halfwidth_fullwidth_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.unknown_idx = -1\n",
    "        if vocab is None:\n",
    "            vocab = {}\n",
    "        self.vocab = vocab\n",
    "        vocab[\"<UNK>\"] = self.unknown_idx\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        return [self.vocab.get(token, self.unknown_idx) for token in text]\n",
    "    \n",
    "    def decode(self, tokens: list[int]) -> str:\n",
    "        inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        return \"\".join([inv_vocab[token] for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "entire_text = \"\"\n",
    "entire_text += string.ascii_letters\n",
    "entire_text += string.digits\n",
    "entire_text += string.punctuation\n",
    "entire_text += string.whitespace\n",
    "entire_text += hiragana\n",
    "entire_text += katakana\n",
    "entire_text += cjk_symbols_punctuation\n",
    "entire_text += halfwidth_fullwidth_forms\n",
    "for kanji in joyo_kanji_info.keys():\n",
    "    entire_text += kanji\n",
    "entire_text = \"\".join(sorted(list(set(entire_text))))\n",
    "for i, char in enumerate(entire_text):\n",
    "    if char not in vocab:\n",
    "        vocab[char] = i\n",
    "tokenizer = CharTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489, 208, 655, 560, 209, 626, 1618, 201, 187, 102]\n",
      "åƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚\n"
     ]
    }
   ],
   "source": [
    "text = \"åƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚\"\n",
    "encoded = tokenizer.encode(text)\n",
    "print(encoded)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 489, 208, 655, 560, 209, 626, 1618, 201, 187, 102, -1]\n",
      "<UNK>åƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚<UNK>\n"
     ]
    }
   ],
   "source": [
    "text = 'äºåƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚ğŸ˜„'\n",
    "encoded = tokenizer.encode(text)\n",
    "print(encoded)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharUTF8Tokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        if vocab is None:\n",
    "            vocab = {}\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        vocab_size = len(vocab) * 1000\n",
    "        for i in range(256):\n",
    "            vocab[f'<utf8_{i}>'] = vocab_size + i\n",
    "\n",
    "    def encode(self, text):\n",
    "        result = []\n",
    "        for char in text:\n",
    "            if char not in self.vocab:\n",
    "                utf_8_num = list(char.encode(\"utf-8\"))\n",
    "                for num in utf_8_num:\n",
    "                    result.append(self.vocab[f'<utf8_{num}>'])\n",
    "            else:\n",
    "                result.append(self.vocab[char])\n",
    "        return result\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        decoded_with_utf_token = [inv_vocab[token] for token in tokens]\n",
    "        decoded_postprocess_utf = []\n",
    "        utf_tokens = []\n",
    "        for token in decoded_with_utf_token:\n",
    "            if token.startswith(\"<utf8_\"):\n",
    "                utf_num = int(token.replace(\"<utf8_\", \"\").replace(\">\", \"\"))\n",
    "                utf_tokens.append(utf_num)\n",
    "            else:\n",
    "                if utf_tokens:\n",
    "                    decoded_postprocess_utf.append(bytes(utf_tokens).decode(\"utf-8\"))\n",
    "                    utf_tokens = []\n",
    "                decoded_postprocess_utf.append(token)\n",
    "        if utf_tokens:\n",
    "            decoded_postprocess_utf.append(bytes(utf_tokens).decode(\"utf-8\"))\n",
    "        return \"\".join(decoded_with_utf_token), \"\".join(decoded_postprocess_utf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_utf8_vocab = dict()\n",
    "entire_text = \"\"\n",
    "entire_text += string.ascii_letters\n",
    "entire_text += string.digits\n",
    "entire_text += string.punctuation\n",
    "entire_text += string.whitespace\n",
    "entire_text += hiragana\n",
    "entire_text += katakana\n",
    "entire_text += cjk_symbols_punctuation\n",
    "entire_text += halfwidth_fullwidth_forms\n",
    "for kanji in joyo_kanji_info.keys():\n",
    "    entire_text += kanji\n",
    "entire_text = \"\".join(sorted(list(set(entire_text))))\n",
    "for i, char in enumerate(entire_text):\n",
    "    if char not in char_utf8_vocab:\n",
    "        char_utf8_vocab[char] = i\n",
    "tokenizer = CharUTF8Tokenizer(char_utf8_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2726228, 2726186, 2726158, 489, 208, 655, 560, 209, 626, 1618, 201, 187, 102, 2726240, 2726159, 2726152, 2726132]\n",
      "<utf8_228><utf8_186><utf8_158>åƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚<utf8_240><utf8_159><utf8_152><utf8_132>\n",
      "äºåƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "text = 'äºåƒ•ã®åå‰ã¯åŸç”°ã§ã™ã€‚ğŸ˜„'\n",
    "encoded = tokenizer.encode(text)\n",
    "print(encoded)\n",
    "decoded_with_utf, decoded = tokenizer.decode(encoded)\n",
    "print(decoded_with_utf)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 74, 81, 81, 84]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# with open(\"char_utf8_vocab.json\", \"w\") as f:\n",
    "#     json.dump(char_utf8_vocab, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# load\n",
    "with open(\"char_utf8_vocab.json\", \"r\") as f:\n",
    "    char_utf8_vocab = json.load(f)\n",
    "tokenizer = CharUTF8Tokenizer(char_utf8_vocab)\n",
    "tokenizer.encode('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0b1100001']\n",
      "['0b11100011', '0b10000001', '0b10000010']\n"
     ]
    }
   ],
   "source": [
    "print([bin(utf_8) for utf_8 in list('a'.encode(\"utf-8\"))])\n",
    "print([bin(utf_8) for utf_8 in list('ã‚'.encode(\"utf-8\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.mext.go.jp/a_menu/shotou/new-cs/__icsFiles/afieldfile/2017/05/15/1385768.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install camelot-py[cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
